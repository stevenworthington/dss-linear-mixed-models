<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Sandwich estimator | Linear Mixed Models</title>
  <meta name="description" content="Sandwich estimator | Linear Mixed Models" />
  <meta name="generator" content="bookdown 0.20 and GitBook 2.6.7" />

  <meta property="og:title" content="Sandwich estimator | Linear Mixed Models" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Sandwich estimator | Linear Mixed Models" />
  <meta name="github-repo" content="stevenworthington/dss-linear-mixed-models" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Sandwich estimator | Linear Mixed Models" />
  
  <meta name="twitter:description" content="Sandwich estimator | Linear Mixed Models" />
  




  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="05_Generalized_linear_models.html"/>
<link rel="next" href="07_Bayesian_models.html"/>
<script src="libs/header-attrs-2.3/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  background-color: #f8f8f8; }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ef2929; } /* Alert */
code span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #c4a000; } /* Attribute */
code span.bn { color: #0000cf; } /* BaseN */
code span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4e9a06; } /* Char */
code span.cn { color: #000000; } /* Constant */
code span.co { color: #8f5902; font-style: italic; } /* Comment */
code span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */
code span.dt { color: #204a87; } /* DataType */
code span.dv { color: #0000cf; } /* DecVal */
code span.er { color: #a40000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #0000cf; } /* Float */
code span.fu { color: #000000; } /* Function */
code span.im { } /* Import */
code span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #204a87; font-weight: bold; } /* Keyword */
code span.op { color: #ce5c00; font-weight: bold; } /* Operator */
code span.ot { color: #8f5902; } /* Other */
code span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */
code span.sc { color: #000000; } /* SpecialChar */
code span.ss { color: #4e9a06; } /* SpecialString */
code span.st { color: #4e9a06; } /* String */
code span.va { color: #000000; } /* Variable */
code span.vs { color: #4e9a06; } /* VerbatimString */
code span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Linear Mixed Models</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Introduction</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#table-of-contents"><i class="fa fa-check"></i>Table of Contents</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#authors-and-sources"><i class="fa fa-check"></i>Authors and Sources</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="01_Fixed_effects_models.html"><a href="01_Fixed_effects_models.html"><i class="fa fa-check"></i>Fixed effects models</a>
<ul>
<li class="chapter" data-level="" data-path="01_Fixed_effects_models.html"><a href="01_Fixed_effects_models.html#lecture-1.2"><i class="fa fa-check"></i>Lecture 1.2</a></li>
<li class="chapter" data-level="" data-path="01_Fixed_effects_models.html"><a href="01_Fixed_effects_models.html#lecture-2.1"><i class="fa fa-check"></i>Lecture 2.1</a>
<ul>
<li class="chapter" data-level="" data-path="01_Fixed_effects_models.html"><a href="01_Fixed_effects_models.html#fixed-effects-regression"><i class="fa fa-check"></i>Fixed effects regression</a></li>
<li class="chapter" data-level="" data-path="01_Fixed_effects_models.html"><a href="01_Fixed_effects_models.html#level-1-predictors"><i class="fa fa-check"></i>Level 1 predictors</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="02_Mixed_effects_models.html"><a href="02_Mixed_effects_models.html"><i class="fa fa-check"></i>Mixed effects models</a>
<ul>
<li class="chapter" data-level="" data-path="02_Mixed_effects_models.html"><a href="02_Mixed_effects_models.html#lecture-2.3"><i class="fa fa-check"></i>Lecture 2.3</a></li>
<li class="chapter" data-level="" data-path="02_Mixed_effects_models.html"><a href="02_Mixed_effects_models.html#lecture-2.4"><i class="fa fa-check"></i>Lecture 2.4</a>
<ul>
<li class="chapter" data-level="" data-path="02_Mixed_effects_models.html"><a href="02_Mixed_effects_models.html#modeling-assumptions"><i class="fa fa-check"></i>Modeling assumptions</a></li>
<li class="chapter" data-level="" data-path="02_Mixed_effects_models.html"><a href="02_Mixed_effects_models.html#centering-your-covariates"><i class="fa fa-check"></i>Centering your covariates</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="02_Mixed_effects_models.html"><a href="02_Mixed_effects_models.html#lecture-2.5"><i class="fa fa-check"></i>Lecture 2.5</a>
<ul>
<li class="chapter" data-level="" data-path="02_Mixed_effects_models.html"><a href="02_Mixed_effects_models.html#part-i-within-versus-between-centering"><i class="fa fa-check"></i>Part I: within versus between centering</a></li>
<li class="chapter" data-level="" data-path="02_Mixed_effects_models.html"><a href="02_Mixed_effects_models.html#part-ii-concept-of-maximum-likelihood"><i class="fa fa-check"></i>Part II: Concept of maximum likelihood</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="02_Mixed_effects_models.html"><a href="02_Mixed_effects_models.html#lecture-2.6"><i class="fa fa-check"></i>Lecture 2.6</a>
<ul>
<li class="chapter" data-level="" data-path="02_Mixed_effects_models.html"><a href="02_Mixed_effects_models.html#confidence-intervals"><i class="fa fa-check"></i>confidence intervals</a></li>
<li class="chapter" data-level="" data-path="02_Mixed_effects_models.html"><a href="02_Mixed_effects_models.html#inference"><i class="fa fa-check"></i>Inference</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="03_Growth_curves.html"><a href="03_Growth_curves.html"><i class="fa fa-check"></i>Growth curves</a>
<ul>
<li class="chapter" data-level="" data-path="03_Growth_curves.html"><a href="03_Growth_curves.html#lecture-3.1"><i class="fa fa-check"></i>Lecture 3.1</a>
<ul>
<li class="chapter" data-level="" data-path="03_Growth_curves.html"><a href="03_Growth_curves.html#growth-curves-1"><i class="fa fa-check"></i>Growth curves</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="03_Growth_curves.html"><a href="03_Growth_curves.html#lecture-3.2"><i class="fa fa-check"></i>Lecture 3.2</a>
<ul>
<li class="chapter" data-level="" data-path="03_Growth_curves.html"><a href="03_Growth_curves.html#quadratic-growth-rb-chapter-6"><i class="fa fa-check"></i>Quadratic growth (R&amp;B chapter 6)</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="03_Growth_curves.html"><a href="03_Growth_curves.html#lecture-3.2-1"><i class="fa fa-check"></i>Lecture 3.2:</a>
<ul>
<li class="chapter" data-level="" data-path="03_Growth_curves.html"><a href="03_Growth_curves.html#model-building"><i class="fa fa-check"></i>Model Building</a></li>
<li class="chapter" data-level="" data-path="03_Growth_curves.html"><a href="03_Growth_curves.html#adding-covariates"><i class="fa fa-check"></i>Adding covariates</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="03_Growth_curves.html"><a href="03_Growth_curves.html#lecture-3.3"><i class="fa fa-check"></i>Lecture 3.3</a>
<ul>
<li class="chapter" data-level="" data-path="03_Growth_curves.html"><a href="03_Growth_curves.html#comparing-models"><i class="fa fa-check"></i>Comparing models</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="04_Many_level_models.html"><a href="04_Many_level_models.html"><i class="fa fa-check"></i>Many level models</a>
<ul>
<li class="chapter" data-level="" data-path="04_Many_level_models.html"><a href="04_Many_level_models.html#lecture-4.1"><i class="fa fa-check"></i>Lecture 4.1</a>
<ul>
<li class="chapter" data-level="" data-path="04_Many_level_models.html"><a href="04_Many_level_models.html#level-2-covariates"><i class="fa fa-check"></i>Level 2 covariates</a></li>
<li class="chapter" data-level="" data-path="04_Many_level_models.html"><a href="04_Many_level_models.html#level-3-covariates"><i class="fa fa-check"></i>Level 3 covariates</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="04_Many_level_models.html"><a href="04_Many_level_models.html#lecture-4.2-a"><i class="fa fa-check"></i>Lecture 4.2 (A)</a></li>
<li class="chapter" data-level="" data-path="04_Many_level_models.html"><a href="04_Many_level_models.html#lecture-4.2-b"><i class="fa fa-check"></i>Lecture 4.2 (B)</a></li>
<li class="chapter" data-level="" data-path="04_Many_level_models.html"><a href="04_Many_level_models.html#lecture-4.3"><i class="fa fa-check"></i>Lecture 4.3</a>
<ul>
<li class="chapter" data-level="" data-path="04_Many_level_models.html"><a href="04_Many_level_models.html#potential-outcomes"><i class="fa fa-check"></i>Potential outcomes</a></li>
<li class="chapter" data-level="" data-path="04_Many_level_models.html"><a href="04_Many_level_models.html#cluster-randomized-trials"><i class="fa fa-check"></i>Cluster Randomized Trials</a></li>
<li class="chapter" data-level="" data-path="04_Many_level_models.html"><a href="04_Many_level_models.html#multisite-experiments"><i class="fa fa-check"></i>Multisite Experiments</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="05_Generalized_linear_models.html"><a href="05_Generalized_linear_models.html"><i class="fa fa-check"></i>Generalized linear models</a>
<ul>
<li class="chapter" data-level="" data-path="05_Generalized_linear_models.html"><a href="05_Generalized_linear_models.html#lecture-5.1"><i class="fa fa-check"></i>Lecture 5.1</a>
<ul>
<li class="chapter" data-level="" data-path="05_Generalized_linear_models.html"><a href="05_Generalized_linear_models.html#poisson-models"><i class="fa fa-check"></i>Poisson models</a></li>
<li class="chapter" data-level="" data-path="05_Generalized_linear_models.html"><a href="05_Generalized_linear_models.html#anatomy-of-a-generalized-linear-model"><i class="fa fa-check"></i>Anatomy of a Generalized Linear Model</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="05_Generalized_linear_models.html"><a href="05_Generalized_linear_models.html#lecture-5.2"><i class="fa fa-check"></i>Lecture 5.2</a>
<ul>
<li class="chapter" data-level="" data-path="05_Generalized_linear_models.html"><a href="05_Generalized_linear_models.html#population-average-versus-individual-school"><i class="fa fa-check"></i>Population average versus individual school</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="05_Generalized_linear_models.html"><a href="05_Generalized_linear_models.html#lecture-5.3"><i class="fa fa-check"></i>Lecture 5.3</a>
<ul>
<li class="chapter" data-level="" data-path="05_Generalized_linear_models.html"><a href="05_Generalized_linear_models.html#marginal-models-population-average-effects-no-random-effects"><i class="fa fa-check"></i>Marginal models: population average effects (no random effects)</a></li>
<li class="chapter" data-level="" data-path="05_Generalized_linear_models.html"><a href="05_Generalized_linear_models.html#latent-growth-models"><i class="fa fa-check"></i>Latent growth models</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="05_Generalized_linear_models.html"><a href="05_Generalized_linear_models.html#lecture-5.4"><i class="fa fa-check"></i>Lecture 5.4</a>
<ul>
<li class="chapter" data-level="" data-path="05_Generalized_linear_models.html"><a href="05_Generalized_linear_models.html#over-dispersion-in-single-level-count-data"><i class="fa fa-check"></i>Over-dispersion in single-level count data</a></li>
<li class="chapter" data-level="" data-path="05_Generalized_linear_models.html"><a href="05_Generalized_linear_models.html#over-dispersion-in-multi-level-count-data"><i class="fa fa-check"></i>Over-dispersion in multi-level count data</a></li>
<li class="chapter" data-level="" data-path="05_Generalized_linear_models.html"><a href="05_Generalized_linear_models.html#subgroup-analysis"><i class="fa fa-check"></i>Subgroup analysis</a></li>
<li class="chapter" data-level="" data-path="05_Generalized_linear_models.html"><a href="05_Generalized_linear_models.html#model-sensitivity-checks"><i class="fa fa-check"></i>Model sensitivity checks</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="06_Sandwich_estimator.html"><a href="06_Sandwich_estimator.html"><i class="fa fa-check"></i>Sandwich estimator</a>
<ul>
<li class="chapter" data-level="" data-path="06_Sandwich_estimator.html"><a href="06_Sandwich_estimator.html#lecture-6.1"><i class="fa fa-check"></i>Lecture 6.1</a></li>
<li class="chapter" data-level="" data-path="06_Sandwich_estimator.html"><a href="06_Sandwich_estimator.html#lecture-6.2"><i class="fa fa-check"></i>Lecture 6.2</a></li>
<li class="chapter" data-level="" data-path="06_Sandwich_estimator.html"><a href="06_Sandwich_estimator.html#lecture-6.3"><i class="fa fa-check"></i>Lecture 6.3</a>
<ul>
<li class="chapter" data-level="" data-path="06_Sandwich_estimator.html"><a href="06_Sandwich_estimator.html#method-1"><i class="fa fa-check"></i>Method 1</a></li>
<li class="chapter" data-level="" data-path="06_Sandwich_estimator.html"><a href="06_Sandwich_estimator.html#method-2"><i class="fa fa-check"></i>Method 2</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="07_Bayesian_models.html"><a href="07_Bayesian_models.html"><i class="fa fa-check"></i>Bayesian models</a>
<ul>
<li class="chapter" data-level="" data-path="07_Bayesian_models.html"><a href="07_Bayesian_models.html#lecture-st.2"><i class="fa fa-check"></i>Lecture ST.2</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Linear Mixed Models</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="sandwich-estimator" class="section level1">
<h1>Sandwich estimator</h1>
<div id="lecture-6.1" class="section level2">
<h2>Lecture 6.1</h2>
<p><strong>OLS and the “Sandwich” Standard Error</strong></p>
<p><strong>A robust Haiku</strong></p>
<p>T-stat looks too good.<br />
Use robust standard errors.<br />
Significance gone.</p>
<p>The standard error and standard error estimate is a function of the randomness in the residuals only — this is the only random part of an OLS model.</p>
<p><strong>Core idea:</strong> use the residuals to get a rough (bad) estimate of the variability of the individual observations, and average to get good overall performance.</p>
<p>Canonical regression formula for OLS:
<span class="math display">\[
Y = \bf{X\beta} + \epsilon
\]</span>
where <span class="math inline">\(\bf{\beta}\)</span> is a p-vector of coefficients to be estimated, <span class="math inline">\(\bf{X}\)</span> is a matrix where there is a column of 1s as the first “covariate” and beta will have an initial coefficient for the intercept corresponding to this column of 1s, <span class="math inline">\(Y\)</span> is an n column of outcomes, and <span class="math inline">\(\epsilon\)</span> is an n vector of residuals.</p>
<p>We can think of a regression (with fixed y) as a single matrix multiply. This is useful when thinking about how the residual <em>vector</em>, <span class="math inline">\(\epsilon = (\epsilon_1, ..., \epsilon_n)\)</span>, is random.</p>
<p>Inverse = division, so the inverse of 5 would be 1/5, because if you multiply 1/5 by 5, you get 1 - which is the identity.</p>
<p>HC2 is best? Maybe HC3.</p>
</div>
<div id="lecture-6.2" class="section level2">
<h2>Lecture 6.2</h2>
<p><strong>Cluster Robust Standard Errors</strong></p>
<p>Building on heteroskedastic robust standard errors (the sandwich estimator) from last lecture…</p>
<p>Cluster robust standard errors:</p>
<ol style="list-style-type: decimal">
<li>We use classic OLS to get <em>population</em> trends.</li>
<li>Then, if we believe clusters are themselves an independent sample, we can use residuals to get very bad estimates of residual structure for each cluster.</li>
<li>We then average to get decent overall estimates.</li>
</ol>
<p>This is a close sister to the sandwich, sharing the same intuition. All of this is only for the <strong>fixed effects</strong>.</p>
<p>Big n by n matrix for residuals, which contains bad but unbiased estimates, then average over these to get better estimates. Also, a small p by p matrix for parameters.</p>
<p>With clustered data, the observations within a cluster are correlated (i.e., the residuals for people within a cluster are similar). So, our residual covariance matrix is <strong>NOT a diagonal matrix</strong>.</p>
<p>This leads to a block diagonal matrix. So, conditional on the overall trends (i.e., the fixed effects), we get a block diagonal matrix for the residuals.</p>
<p>Our estimate of <span class="math inline">\(\hat{\beta}\)</span> is going to be the sum of a bunch of <span class="math inline">\(\hat{\beta}\)</span> for each cluster group - because we are essentially fitting separate regressions to each group and then aggregating the coefficients (while weighting them).</p>
<p>The random intercept model says that the off-diagonals in the VCV matrix are the same, but when using cluster robust standard errors we say that we don’t know what the off-diagonals are.</p>
<p>When do we get big standard errors on our fixed effects? We get large variances compared to OLS when:</p>
<ol style="list-style-type: decimal">
<li>Covariates vary mostly across cluster rather than within cluster (note how a group level covariate only varies cross cluster!).</li>
<li>Errors within cluster are correlated so the omegas are non-zer (generally positive).</li>
<li><span class="math inline">\(N_g\)</span> is large (many units inside a cluster).</li>
<li>Within-cluster regressor and error correlations are the same sign (which is typical).</li>
</ol>
<p>Take away messages:</p>
<ol style="list-style-type: decimal">
<li>There can be a great loss of efficiency in OLS estimation if errors are correlated within cluster. (“More observations in the cluster doesn’t tell you much that is new”)</li>
<li>But sometimes these methods give you <em>smaller</em> errors than you would expect</li>
</ol>
<p>Rule of thumb — specify the clusters at the highest level. If you don’t, then you’ll be ignore some dependence between your units.</p>
<p>Bell reading - fixed effects regression with cluster robust standard errors versus MLM.</p>
</div>
<div id="lecture-6.3" class="section level2">
<h2>Lecture 6.3</h2>
<p><strong>Fitting models with complex residual error structure</strong></p>
<p><strong>Dataset:</strong> national youth survey.</p>
<p>We have longitudinal data measured at specific <strong>waves</strong>.</p>
<p>We can fit a linear growth model, but we may worry that our within-student residuals are not iid (i.e., adjacent residuals tend to be similar - have the same sign).</p>
<p>Two methods:
1. overall residual <span class="math inline">\(u_{ti}\)</span> (using cluster robust standard errors)
2. within-student residuals <span class="math inline">\(r_{0i}\)</span> <span class="math inline">\(r_{1i}\)</span> (using MLM)</p>
<div id="method-1" class="section level3">
<h3>Method 1</h3>
<p>Modeling:
<span class="math display">\[
u_{ti} = r_i + \epsilon_{ti}, t = 1,...,5
\]</span></p>
</div>
<div id="method-2" class="section level3">
<h3>Method 2</h3>
<p>R&amp;B page 190</p>
<ol style="list-style-type: decimal">
<li>Compound symmetry = distribution of the <span class="math inline">\(u\)</span> around the black line.</li>
<li>AR1</li>
<li>random slope - produces heteroskedastic residuals, since the slopes fan out over time</li>
<li>random slopes with heteroskedasticity</li>
<li>random slopes with unstructured</li>
</ol>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="05_Generalized_linear_models.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="07_Bayesian_models.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/IQSS/dss-linear-mixed-models/edit/master/06_Sandwich_estimator.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["Linear_mixed_models.pdf", "Linear_mixed_models.epub"],
"toc": {
"collapse": "section",
"scroll_highlight": true
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
