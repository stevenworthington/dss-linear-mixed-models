[
["index.html", "Linear Mixed Models Introduction Table of Contents Authors and Sources", " Linear Mixed Models August 2020 Introduction Reports in Rmarkdown: https://www.stat.cmu.edu/~cshalizi/rmarkdown/ Math in Rmd: https://www.calvin.edu/~rpruim/courses/s341/S17/from-class/MathinRmd.html Rmd example: http://www.math.mcgill.ca/yyang/regression/RMarkdown/example.html Table of Contents Here, we outline how the guide is organized into parts. First, we… Second, we… Lastly, we… Here we provide an outside link to important content which puts some useful information for this tutorial/workshop at our fingertips. Here we specify where people can provide feedback! Please email help@iq.harvard.edu Authors and Sources Here we acknowledge a few people who helped make this tutorial/workshop possible. We also reference any sources that material was taken from. ## Loading required package: Matrix "],
["01_Fixed_effects_models.html", "Fixed effects models Lecture 1.2 Lecture 2.1", " Fixed effects models Lecture 1.2 \\[ MA_i = \\beta_0 + \\beta_1*SES + \\beta_2*I(id=2)... \\beta_k*I(id=k) \\] School level fixed effects — allow each school to differ. They will raise or lower the slope of SES depending on the school. The indicators adjust for school-level differences — called fixed effects. This “completely pools” the SES relationship — it’s the same for each school. THIS IS INCORRECT — FIXED EFFECTS RESULT IN NO POOLING Drop the intercept when using fixed effects? But this would force SES through the origin, no? Have NOT pooled the intercept, but HAVE completely pooled the slope. Models impose structure - if the structure is not true, our model estimates can be wrong. fit1 &lt;- lm(math ~ ses * id - 1 - ses, data = hsb) # gives you k slopes and intercepts, where k is the number of schools. Point estimates the same as fitting each school separately. But, when fitted together, you get one estimate for the residual variance, but when fitted separately, you get different residual variances for each school. Sorting out the measurement error versus the structure - are the slopes really different or do they just look different? Inference - separating what is real from what is random. dplyr Data pipeline - data gets handed to the next thing in line, then the output of that gets handed to the next thing in line. Overdispersion: Dots stacked up. Jitter the dots. Each dot is average of some school. More variance you have across the dots, the more overdispersion you have. How much modeling flexibility is the right amount? Need a model flexible enough to capture the main structure of the data, but not so flexible that they’re hard to estimate. Lecture 2.1 Aggregation is unsatisfying: underpowered biased heteroscedastic Multilevel models are really lots of models tied together. classic estimate of average for each county Single county \\(j\\) \\(n_j\\) houses \\(Y_{ij}, Y_ni\\) -&gt; \\(stdev(Y_i... Y_nj) = S_j\\) -&gt; \\(\\hat{Y}_j\\) -&gt; \\(\\hat{SE} = \\frac{S_j}{sqrt(n_j)}\\) Fixed effects regression Take average value of radon for each county then add value for each house - this is fixed effects regression. \\[ house_i = \\alpha_j[i] + \\epsilon_i \\] Fixed effects assumes homoscedasticity of the error around the counties - county level variances are the same - with this assumption, we can estimate just one error term for the model. Unlike when you model counties in separate regression models - where you have a separate error term for each model and therefore allow the variance within eaxch county to be different (like GLS). Shrink estimates towards a common mean. House \\(i\\) in county \\(j[i]\\). \\[ y_i = \\alpha_j[i] + \\epsilon_i \\\\ \\epsilon_i ~ N(0, \\sigma^2_\\alpha) \\\\ \\alpha_j ~ N(\\mu, \\sigma^2_\\alpha) %% &quot;soft constraint&quot;: this ties the intercepts together \\] \\(\\alpha_j\\) are the county means. \\(\\mu\\) is the grand mean of the county means (NOT the same as the mean of all the houses). \\(\\sigma^2_\\alpha\\) is the variance of the county means. Shrinkage - a weighted average of the mean for the county and the grand mean of the counties. Shrinkage = empirical Bayes estimate. Tend to be underdispersed, compared to the overdispered fixed effects estimates. Bias-variance trade off - can introduce some bias into the estimates in return for removing a lot of variance. This will result in better estimates overall. Level 1 predictors Basement floor indicator. coef(model)$county # get the empirical Bayes estimates for each county "],
["02_Mixed_effects_models.html", "Mixed effects models Lecture 2.3 Lecture 2.4 Lecture 2.5 Lecture 2.6", " Mixed effects models Lecture 2.3 gender gap and math achievement Two level notation \\[ math_{ij} = \\beta_{0j} + \\beta_1*female_{ij} + \\epsilon_{ij} \\\\ \\beta_{0j} = \\mu + U_{0j} \\] where \\(\\epsilon \\sim N(0, \\sigma^2)\\) and \\(U_{0j} \\sim N(0, \\sigma^2)\\) Single level notation \\[ math_{ij} = \\mu + \\beta1*female_{ij} + U_{0j} + \\epsilon_{ij} \\] where \\(U_{0j}\\) is the random intercept. mod1 &lt;- lmer(math ~ 1 + female + (1 | id), data = hsb) summary(mod1) ## Linear mixed model fit by REML [&#39;lmerMod&#39;] ## Formula: math ~ 1 + female + (1 | id) ## Data: hsb ## ## REML criterion at convergence: 47056 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -3.1956 -0.7506 0.0379 0.7704 2.6211 ## ## Random effects: ## Groups Name Variance Std.Dev. ## id (Intercept) 8.169 2.858 ## Residual 38.850 6.233 ## Number of obs: 7185, groups: id, 160 ## ## Fixed effects: ## Estimate Std. Error t value ## (Intercept) 13.3449 0.2547 52.400 ## female -1.3590 0.1714 -7.927 ## ## Correlation of Fixed Effects: ## (Intr) ## female -0.350 # Intercept is \\mu, \\beta_1 is female, 1 in parentheses is the random intercept (U_{0j}) Extend to Catholic schools (sector variable): Two level notation \\[ math_{ij} = \\beta_{0j} + \\beta_1*female_{ij} + \\epsilon_{ij} \\\\ %% level 1, where \\epsilon \\sim N(0, \\sigma^2) \\beta_{0j} = \\mu + U_{0j} + \\gamma_{01}*sector_j \\\\ %% level 2, where U_{0j} \\sim N(0, \\sigma^2) \\beta_{1j} = \\gamma_{10} + \\gamma_{11}*sector_j %% level 2, add sector at level 2 \\] First subscript tells us which beta, Second subscript tells us which which piece inside the equation - so sequentially from 0 to n for each term. Single level notation \\[ math_{ij} = \\beta_{0j} + \\beta_1*female_{ij} + \\epsilon_{ij} \\\\ %% level 1 = (\\gamma_{00} + \\gamma_{01}*sector_j + U_{0j}) + (\\gamma_{10} + \\gamma_{11}*sector_j) + female_j + \\epsilon_{ij} \\\\ = \\gamma_{00} + \\gamma_{01}*sector_j + U_{0j} + \\gamma_{10}*female + \\gamma_{11}*sectorFemale_j + \\epsilon_{ij} \\] The coefficient for the interaction is \\(\\gamma_{11}\\). mod2 &lt;- lmer(math ~ 1 + sector + female + sector : female + (1 | id ), data = hsb) summary(mod2) ## Linear mixed model fit by REML [&#39;lmerMod&#39;] ## Formula: math ~ 1 + sector + female + sector:female + (1 | id) ## Data: hsb ## ## REML criterion at convergence: 47017.2 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -3.15363 -0.75077 0.03403 0.76707 2.61443 ## ## Random effects: ## Groups Name Variance Std.Dev. ## id (Intercept) 6.286 2.507 ## Residual 38.849 6.233 ## Number of obs: 7185, groups: id, 160 ## ## Fixed effects: ## Estimate Std. Error t value ## (Intercept) 12.1714 0.3056 39.831 ## sectorcatholic 2.6177 0.4667 5.608 ## female -1.4818 0.2092 -7.085 ## sectorcatholic:female 0.3338 0.3618 0.922 ## ## Correlation of Fixed Effects: ## (Intr) sctrct female ## sectorcthlc -0.655 ## female -0.360 0.235 ## sctrcthlc:f 0.208 -0.402 -0.578 # Intercept is \\mu, \\beta_1 is female, 1 in parentheses is the random intercept (U_{0j}) Covary - having an unusual intercept can be predictive of having an unsual slope - knowing one tells you about the other. Intercepts and slopes can covary - pulled from a multivariate normal distribution. Intercept and slope are tied together. Covariance = correlation on scale of original variables Correlation = unitless mod3 &lt;- lmer(math ~ 1 + ses + (1 + ses | id ), data = hsb) summary(mod3) ## Linear mixed model fit by REML [&#39;lmerMod&#39;] ## Formula: math ~ 1 + ses + (1 + ses | id) ## Data: hsb ## ## REML criterion at convergence: 46640.4 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -3.12272 -0.73046 0.02144 0.75610 2.94356 ## ## Random effects: ## Groups Name Variance Std.Dev. Corr ## id (Intercept) 4.8287 2.1974 ## ses 0.4129 0.6426 -0.11 ## Residual 36.8301 6.0688 ## Number of obs: 7185, groups: id, 160 ## ## Fixed effects: ## Estimate Std. Error t value ## (Intercept) 12.6650 0.1898 66.71 ## ses 2.3938 0.1181 20.27 ## ## Correlation of Fixed Effects: ## (Intr) ## ses -0.045 # random intercept and slope for ses # to get covariance, you can multiply the correlation between intercept and slope with the intercept variance and then the slope variance Empirical Bayes estimates over-shrink. They provide too much pooling. Can simulate from the model to mitigate this. So, generate random schools from the model to simulate more accurately the variation. Lecture 2.4 Modeling assumptions Assumptions are less important for describing trends in data, rather than estimating causal effects. Level 1 exogeneity: \\(r_{ij} \\overset{i.i.d.}{\\sim} N(0, \\sigma^2)\\) &lt;– classic OLS assumptions –&gt; Level 2 exogeneity: \\(Cov(X_{qij}, r_{ij} = 0\\) Level 1 homoskedasticity: \\(u_j = (u_{0j}, ..., u_{Qj})&#39; \\overset{i.i.d}{\\sim} N()\\) Level 2 homoskedasticity: Uncorrelation of residuals: \\(Cov(r_{ij}, u_{qj}) = 0\\) &lt;– cross level assumptions –&gt; Uncorrelation of random effects: $Cov(X_{qij}, $ Uncorrelation of residuals with random effects: Normal distribution of random effects (less important): mod4 &lt;- lmer(math ~ 1 + female + sector + ses + sector : ses + meanses + (1 + ses | id), data = hsb) summary(mod4) ## Linear mixed model fit by REML [&#39;lmerMod&#39;] ## Formula: math ~ 1 + female + sector + ses + sector:ses + meanses + (1 + ## ses | id) ## Data: hsb ## ## REML criterion at convergence: 46462.9 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -3.08893 -0.73219 0.02407 0.76266 2.92613 ## ## Random effects: ## Groups Name Variance Std.Dev. Corr ## id (Intercept) 2.11395 1.454 ## ses 0.03096 0.176 0.65 ## Residual 36.60081 6.050 ## Number of obs: 7185, groups: id, 160 ## ## Fixed effects: ## Estimate Std. Error t value ## (Intercept) 12.7905 0.2087 61.299 ## female -1.1824 0.1616 -7.317 ## sectorcatholic 1.2945 0.2927 4.423 ## ses 2.7274 0.1428 19.100 ## meanses 3.0441 0.3665 8.306 ## sectorcatholic:ses -1.3062 0.2097 -6.229 ## ## Correlation of Fixed Effects: ## (Intr) female sctrct ses meanss ## female -0.396 ## sectorcthlc -0.636 -0.012 ## ses 0.090 0.047 -0.040 ## meanses 0.213 0.028 -0.335 -0.212 ## sctrcthlc:s -0.105 -0.014 0.064 -0.645 -0.020 Understanding assumptions by breaking them: Level 1 heteroskedasticity - if high SES students have more variable math achievement than low SES students. Level 2 heteroskedasticity - if catholic schools are more variable (in their random offsets) than public schools. Level 1 exogeneity: if the association between SES and math acheivement is not linear. Level 2 exogeneity: this one is fine, as long as we have categorical level-2 predictors. (with categorical predictirs, we are always ``linear’’). For continuous level-2 predictors, we would need a linear relationship again. Assumptions 2, 4, and 6 can cause bias (i.e., relationship between variables in the ``structural’’ part of the model and the error terms. While assumptions 1, 3 and 5 can mess up variance components (ie., consistency of the standard errors, accuracy of the variance estimates, accuracy of confidence intervals and hypothesis tests). Centering your covariates Intercepts \\[ income_i = \\beta_0 + \\beta_1SAT_i + \\epsilon_i \\\\ \\hat{\\beta_0} = 1000 \\\\ \\hat{\\beta_1} = 3 \\] When intercepts are far away, we get a slight change in slope associated with a large change in intercept. They are quite correlated. With centering, changing the slope doesn’t really change the intercept. The intercept is more the overall mean, and therefore useful. Decoupling slope and intercept stops each one from messing with the other and aids in estimation - can end up with high or low random effects correlations if not centered. If you see that the random intercept and slope are correlated after mean centering, then this means the correlation is something structural about the data, not something mechanical about estimation. Group mean centering: intercepts are now means of the whole group (i.e., school). Individual level covariate now measures departure from the group the individual is in. \\(y_{ij} = \\alpha_j + \\beta_j(X_{ij} - \\bar{X}_j) + \\epsilon_{ij}\\) where \\(\\bar{X}_j = 500\\) Grand mean centering: intercepts are now adjusted means. \\(y_{ij} = \\alpha_j + \\beta_j(X_{ij} - \\bar{X}) + \\epsilon_{ij}\\) where \\(\\bar{X} = 500\\). Within versus between centering: Lecture 2.5 Part I: within versus between centering Dataset - birthweight and smoking (Swedish dataset). Level 1 - babies. Level 2 - mother. Can do between mother comparisons and within mother comparisons. Think about regression as a form of matching. Between mother confounders will be time invariant, while within mother confounders will be time variant. Why did the mother smoke for one pregnancy but not the other? Do we have a variable that identifies the reason? Like was she large and sedantary, then became a marathon runner. Cannot do age to age within comparisons - same mother giving birth at age 20 cannot be compaared to her later self giving birth at age 40 - this would need to be between mother. Though you could use age-adjusted birthweights for within comparisons. Estimating between: aggregate data to group level, then regress average birthweight onto the averages of the predictors. A kind of dose-response model. Averaging works for linear models. Estimating within: take out between variation and then regress - this is fixed effects regression. Alternative - within-group recentering (subtract mother-level means from outcomes?? and all covariates - see RH&amp;S pg 145). Estimating both with a MLM: We can allow for different within and between effects. So for birth \\(i\\) of mother \\(j\\): \\[ y_{ij} = \\beta_1 + B^W(S_{ij} - \\bar{S}_{.j}) + \\beta^B\\bar{S}_{.j} + \\xi_j + \\epsilon_{ij} \\] with \\(S_{ij}\\) smoking status and \\(\\bar{S}_j\\) average smoking status for mother \\(j\\). Here the notation is that \\(\\gamma_0\\) is \\(\\beta_1\\) (the fixed effects intercept) and \\(u_j\\) is \\(\\xi_j\\) (the random effect residual - random deviations for the \\(j\\) groups from the fixed effects intecept). \\(\\beta_1 = 3238gms\\), \\(\\beta^W = -105\\), \\(\\beta^B = 183\\). dat &lt;- dat %&gt;% group_by(mid) %&gt;% mutate(smokem = mean(smoke), smokec = smoke - smokem) mod5 &lt;- lmer(birthweight ~ 1 + smokec + smokem + (1 | mid), data = dat) Deviations from cluster means are automatically uncorrlelated with the group means - solution to one of the model assuptions (this is the hybrid model). Now the same model with the HSB data: \\[ y_{ij} = \\beta_{0j} + \\beta_wSES_{ij} + \\beta_b\\bar{SES}_j + \\epsilon_{ij} \\\\ \\beta_{ij} = \\gamma_0 + u_{0j} \\] Within coef estimates slope inside the school. Between coef estimates how the averages of the school relate to the outcome. Contextual effect: The expected difference in outcomes from being in school 2 versus school 1 (but with the same SES) - in R&amp;B pg 140. The between effect is basically the contextual effect plus the within effect. If you group mean center the within variable, then the between variable becomes and estimate of the contextual effect - is this right? Part II: Concept of maximum likelihood The model: a description or recipe of how the data might have come to be (a data generating process). The model tells us what predictions are possible. The parameters: numbers that makes this general recipe more specific. What parameters of this model make your data more likely? Lecture 2.6 Inference for MLMs We get 3 things from MLMs: fixed effects variance and covariance parameters (\\(\\tau\\)) - variances and covariances of the hyperparameters With empirical Bayes as a second step, estimated random effects for each group (not the variances, but the actual estimates for each group). Inference for these estimates is very shaky - generally don’t do it. Second level predictors modify intercepts or slopes. If they modify slopes, then that is an interaction with the first level predictor associated with that slope - it moderates the slope of the first level predictor. See Chapter 4 in BR book. confidence intervals normal approximation: \\[ \\sqrt{n} \\left( \\hat{\\beta} - \\beta \\right) \\rightarrow N(0, \\tau^2) \\\\ SE = \\frac{\\tau}{\\sqrt{n}} \\] As sample size grows, the estimated parameters will be normally distributed about the true parameters, and the variance will shrink with the sample size towards an estimable value. If the sampling distribution is relatively symmetric and bell-shaped, a 95% confidence interval can be estimated using: \\[ statistic \\pm 2 \\times \\widehat{SE} \\] Confidence intervals don’t tell you whether you’re right or wrong for a given project, but rather how often you’ll be right over time. Normal approximation assumes that we know \\(\\tau\\), but we don’t, we estimate it. variance covariance estimates: Uncertainty estimnates are hard to get and are generally unreliable. But, we can test whether the estimates are different from zero. There are no standard errors for variance parameters - because standard errors only really make sense if the distribution is the estimator is more or less symmetric. But, for variance parameters, the distribution is skewed (bounded at zero). This boundary distorts normality. profile likelihood confidence intervals: Basically asks, “what is likely if we let other parameters fit as best they can?”. Lays down a number line and sets grid points, then iterates over the grid and determines which values on the grid are believable. Inference Compare your data to what you would have gotten were your hull hypothesis true (i.e., compare what we have to what we should have had). Likelihood ratio tests best Wald tests good, but not good for variance parameters with skewed distributions ANOVA / F tests score tests P-values: Gelman “There are no zeros in social science”. Wald test (t-test): \\[ t = \\frac{\\hat{\\beta} - \\beta_{hyp}}{\\widehat{se}(\\hat{\\beta})} \\] The chance of reaching your “extreme value” \\(t\\) by chance if the null hypothesis is correct. A problem with t-tests - degrees of freedom. \\[ H_0 : \\gamma_{10} = 0 \\] where: \\[ \\beta_{1j} = \\gamma_{10} + u_{1j} \\] The above null should be extended to include a test of whether the random effects variance for \\(u_{1j}\\) is also zero - in other words, no variance around the fixed effect of zero. By hand: 2 * pnorm(t, lower.tail = FALSE) The number of degrees of freedom tells you which parameters were harder or easier to estimate given the clustered nature of the data. Group mean centering can increase degrees of freedom. Likelihood ratio test: if the likelihoods are basically the same, we accept the null. If the constrained model fits like crap, then we reject the null. To test, we compare the ratio of likelihoods. Basic idea: if \\(\\gamma_{00}\\) is actually 0, then omitting it from the model shouldn’t make much difference. \\[ D = -2log \\frac{L(\\textrm{simple model})}{L(\\textrm{complex model})} \\] The likelihood ratio statistic has a \\(\\chi^2\\) distribution: \\[ D \\sim \\chi^2 \\] "],
["03_Growth_curves.html", "Growth curves Lecture 3.1 Lecture 3.2 Lecture 3.2 Lecture 3.3", " Growth curves Longitudinal data and growth curves Lecture 3.1 Individuals are level 2, time is level 1. Observations about individuals that do not change are level 2, while observations about individuals that do change are level 1. Essentially, individuals are sampled, and then time points within individuals are sampled (not they’re not really sampled). Clustered data: we observed a bunch of students in a school. The students have no order. They are independent within the school. Longitudinal data: we observe a bunch of times. The times are ordered. They are not independent within the student. This ordering of observations is meaningful. So, time points closer to each other are more correlated with each other. Visualizations important with longitudinal data. Always look at your individuals by plotting their outcome data over time. Marginal model: summary / average accross all individuals. Read Willet and Singer book chapters. Panel studies: track everyone at the same sequence of time points. Timepoints are called “waves”. Cohort studies: follow a group. But, check-in times can be variable. Balance: For panel data, when there is an observation for each person at each time point. Growth curves R&amp;B pg 164 For each child, they have initial knowledge \\(\\pi_{0i}\\) and rate of increase \\(\\pi_{1i}\\). Make the intercept meaningful - at onset of preschool or something. R&amp;B pg 163-164 Classic random slope model: \\[ Y_{ti} = \\pi_{0i} + \\pi_{1i}\\alpha_{ti} + \\epsilon_{ti} \\\\ \\epsilon_{ti} \\sim N(0, \\sigma^2) \\\\ \\pi_{0i} = \\beta_{00} + r_{0i} \\\\ \\pi_{1i} = \\beta_{10} + r_{1i} \\\\ (r_{0i}, r_{1i}) \\sim N(\\bf{0}, \\Sigma) \\] Fixed effects: \\(\\beta_{00}\\), \\(\\beta_{10}\\) Variance components: \\(\\sigma^2\\), \\(\\tau_{00}\\), \\(\\tau_{11}\\), \\(\\tau_{10}\\) Betas are now parameters at level 2 because we added in another level below individuals. Lecture 3.2 Quadratic Growth Models (Part I) Questions to ask: 1. Is there variation? — are these children different from each other? 2. What explains this variation? — what variables explain why children are different from one another? 3 random effects per student: 1. Random intercept (\\(\\pi_{0i}\\)) 2. Random slope (\\(\\pi_{1i}\\)) 3. Random acceleration /curvature (growth) (\\(\\pi_{2i}\\)) Data is structured like this: ID \\(\\alpha\\) \\(\\gamma\\) Home Language HRS 101 \\(\\alpha_{1, 101}\\) 0 -0.5 0 80 101 \\(\\alpha_{2, 101}\\) 4 0.2 0 80 101 \\(\\alpha_{3, 101}\\) 5 0.4 0 80 101 \\(\\alpha_{4, 101}\\) 8 0.7 0 80 208 \\(\\alpha_{1, 208}\\) -0.8 1 80 First column after ID is time. Two level notation: (here, \\(a\\) is age - a level one predictor) \\[ Y_{ti} = \\pi_{0i} + \\pi_{1i}a_{ti} + \\epsilon_{ti} \\\\ \\epsilon_{ti} \\sim N(0, \\sigma^2) \\\\ \\pi_{0i} = \\beta_{00} + \\beta_{01}X_i + r_{0i} \\\\ \\pi_{1i} = \\beta_{10} + \\beta_{11}X_i + r_{1i} \\\\ (r_{0i}, r_{1i}) \\sim N(\\bf{0}, \\Sigma) \\] Single level notation: \\[ Y_{ti} = \\pi_{0i} + \\pi_{1i}a_{ti} + \\epsilon_{ti} \\\\ = (\\beta_{00} + \\beta_{01}X_i + r_{0i}) + (\\beta_{10} + \\beta_{11}X_i + r_{1i}) + a_{ti} + \\epsilon_{ti} \\\\ = \\beta_{00} + \\beta_{01}X_i + r_{0i} + \\beta_{10}a_{ti} + \\beta_{11}X_i\\alpha_{ti} + r_{1i}a_{ti} + \\epsilon_{ti} \\\\ = \\beta_{00} + \\beta_{01}X_i + \\beta_{10}a_{ti} + \\beta_{11}X_ia_{ti} + (r_{0i} + r_{1i}a_{ti} + \\epsilon_{ti}) \\] The random effects in the parentheses on the final line can be thought of as residuals. Prediction: \\[ X_i = 2, a_{ti} = 5 \\\\ \\beta_{00} + \\beta_{01}2 + \\beta_{10}5 + \\beta_{11}2.5 \\] mod7 &lt;- lmer(Y ~ 1 + age * (language + hours) + (1 + age | StudentID), data = dat) When using growth models, we may not care about level 1. Level 2 is where we get at the question of growth. Here, \\(t\\) is the observation number. \\[ Y_{ti} = \\pi_{0i} + \\pi_{1i}a_{ti} + \\epsilon_{ti} \\\\ \\epsilon_{ti} \\sim N(0, \\sigma^2) \\\\ \\pi_{0i} = \\beta_{00} + \\beta_{01}LANG_i + \\beta_{02}HRS_i + r_{0i} \\\\ \\pi_{1i} = \\beta_{10} + \\beta_{11}LANG_i + \\beta_{12}HRS_i + r_{1i} \\\\ (r_{0i}, r_{1i}) \\sim N(\\bf{0}, \\Sigma) \\] When looking at growth rates over time, a small growth rate difference can mean a lot, since the difference in growth rate gets compounded over time. It’s best to get some predictions for each kid over the full length of time, then compare. Quadratic growth (R&amp;B chapter 6) Research question: Describe the association between maternal speech and child’s vocabulary. Very important to pick where the intercept is for growth models — need to mean center. L is an important centering decision - in this case, L = 12 months (that’s the intercept). But, may be better to put L within the bounds of the observed data. \\(\\pi_{0i}\\) = status at L \\(\\pi_{1i}\\) = instantaneous (average) growth at L \\(\\pi_{2i}\\) = curvature / acceleration Unconditional Quadratic Growth Model: \\[ Y_{ti} = \\pi_{0i} + \\pi_{1i}(a_{ti} - L) + \\pi_{2i}(a_{ti} - L)^2 + \\epsilon_{ti} \\\\ \\epsilon_{ti} \\sim N(0, \\sigma^2) \\\\ \\pi_{0i} = \\gamma_{00} + u_{0i} \\\\ \\pi_{1i} = \\gamma_{01} + u_{1i} \\\\ \\pi_{2i} = \\gamma_{02} + u_{2i} \\\\ (u_{0i}, u_{1i}, u_{2i}) \\sim N(\\bf{0}, \\Sigma) \\] Three random effects — all correlated. We have a fixed centering constant \\(L\\) (this is a constant chosen by you, not a parameter). Anything with an \\(i\\) subscript is for an individual student. Anything without a subscript is a fixed effect — this is the shared structual component of the model. Number of parameters we are estimating: 3 fixed effects: \\(\\gamma_{00}, \\gamma_{01}, \\gamma_{02}\\) 6 random effects: the diagonals of the matrix: \\(\\tau_{00}, \\tau_{11}, \\tau_{22}\\). next are the covariances: \\(\\tau_{01}, \\tau_{02}, \\tau_{12}\\) 1 residual term: \\(\\epsilon_{ti}\\) Lecture 3.2 Quadratic Growth Models (Part II) R&amp;B Chapter 6 pg 169-176 Anatomy of a quadratic curve: \\[ y = \\pi_{oi} + \\pi_{1i}(X - L) + \\pi_{2i}(X - L)^2 \\\\ L = 19 \\\\ X = {18, 19, 20} \\\\ \\pi_{0i} = 1, \\pi_{1i} = 2, \\pi_{2i} = 0.5 \\] Evaluate y at the above Xs and graph it. Predict vocabulary for an average / typical child (assuming the random effects and residuals are zero) at X = 20 and X = 12: \\[ \\hat{y} = -45.05 + 12.14(20 - 12) + 1.84(20 - 12)^2 \\\\ = 170 \\\\ \\hat{y} = -45.05 + 12.14(12 - 12) + 1.84(12 - 12)^2 \\\\ = -45.05 \\] If the random effects are not normally distributed (the ones from the coef() function in R), then this is evidence of model miss-specification. Probably, there is some omitted variable in the structural part of the model. If the random effects are grouped at the extremes, this may indicate that there’s a missing grouping variable in the fixed effects part of the model. Rate of growth at age \\(a\\) for kid \\(i\\) is the derivitive of our curve at age \\(a\\). Model Building How can we get a nice simple model given our data? (Cat lego picture) Model refinements: Drop the intercept — no overall intercept or random intercept. We force the regression through the origin, which if we’ve centered the data at \\(L = 12\\) the origin will be 12. So, kids at age 12 will have zero vocabularly. Our residuals only changed a little bit. Set expected rate of growth at age 12 to zero. (i.e., take out the linear fixed effect term, but leave in the linear random effect). Our residuals only changed a little bit. Adding covariates Can we explain our acceleration? Is maternal speech predictive of growth? Dropping main effects — a design decision: M4A.2 &lt;- lmer(vocab ~ 0 + age12sq:sex + age12sq:logmom + (0 + age12 + age12sq | per), dat = dat.g0) The above model says that mother’s vocabularly will increase the accelation of child’s acquisition of vocabularly. But, that the fixed rate of growth (i.e., linear growth) is fixed at zero. Lecture 3.3 piecewise linear growth model and model comparison (AIC) Reading: Faraway ch 9. Rabe-Hesketh &amp; Skrondal: pp 227-264 logitudinal data structure, pp 278-282 missing data, pp 293-311 marginal models and error structures. Time varying questions are harder than time invariant questions. screenreg() from textregp package (can it output SDs instead of variances?) Positive covariance term means that higher random slope goes with higher random intercept - so kids that start with higher reading skills also learn at a faster rate. Even if the difference in learning rate is small between the kids, over time this can equate to a large difference in their reading skills. \\[ covariance(A, B) = correlation \\times SD_A \\times SD_B \\\\ correlation = \\frac{covariance}{SD_A \\times SD_B} \\] mod9 &lt;- lmer(reading ~ 1 + time + gender + time : gender + (1 + time | id), data = dat) Comparing models \\[ 1 - Var(conditional model) / Var(unconditional model) = proportion of variance explained \\] Parametric growth curves The most complex model you can entertain is one where the number of parameters is n-1, where n is the number of observations. So if there are 4 data points for each kid, you can have at most a quadratic model. Can use a log transform to have a steep start to the growth, then have it level out. Selecting a growth curve use theory / research question use a curve that works well overall simple is better Piecewise growth Piecewise growth is inherently cumulative. \\[ reading_{it} = \\pi_{0i} + \\pi_{1i}TimeA_{it} + \\pi_{2i}TimeB_{it} + \\epsilon_{it} \\] Look at cumulative school time and cumulative summer time (do book keeping based on data collection) Option 1: school time / summer time separately: \\[ reading_{it} = \\pi_{0i} + \\pi_{1i}School_{it} + \\pi_{2i}Summer_{it} + \\epsilon_{it} \\\\ \\pi_{0i} = \\gamma_{00} + u_{0i} \\\\ \\pi_{1i} = \\gamma_{10} + u_{1i} \\\\ \\pi_{2i} = \\gamma_{20} + u_{2i} \\] mod10 &lt;- lmer(reading ~ 1 + school + summer + (1 + school + summer | id), data = dat) Option 2: increment / decrement — like an interaction for the change in slope at a specific time point: \\[ reading_{it} = \\pi_{0i} + \\pi_{1i}Time_{it} + \\pi_{2i}Summer_{it} + \\epsilon_{it} \\\\ \\pi_{0i} = \\gamma_{00} + u_{0i} \\\\ \\pi_{1i} = \\gamma_{10} + u_{1i} \\\\ \\pi_{2i} = \\gamma_{20} + u_{2i} \\] mod11 &lt;- lmer(reading ~ 1 + time + summer + (1 + time + summer | id), data = dat) These two models are the same; they just have different parameterizations. "],
["04_Many_level_models.html", "Many level models Lecture 4.1 Lecture 4.2 (A) Lecture 4.2 (B) Lecture 4.3", " Many level models Lecture 4.1 Many level models (&gt;3 levels) Case study: student growth for student nested in schools — READS data. Student level predictors, but students are within schools. Research questions: Do students at different schools grow at different rates, on average? Do students identified at English learners language learners grow at different rates than other students, and does that vary by school? (this requires a student-level predictor) Do students at high poverty schools have systematically different rates of growth than students at low poverty schools (this requires a school-level predictor). Three-level model: \\[ read_{ijt} = \\pi_{0ij} + \\pi_{1ij}time_{ijt} + \\color{darkgreen}{\\epsilon_{ijt}} \\\\ \\color{darkgreen}{\\epsilon_{ijt}} \\sim N(0, \\sigma^2) \\\\ \\pi_{0ij} = \\beta_{00j} + \\color{darkgreen}{u_{0ij}} \\\\ \\pi_{1ij} = \\beta_{10j} + \\color{darkgreen}{u_{1ij}} \\\\ \\beta_{00j} = \\color{darkred}{\\gamma_{000}} + \\color{darkgreen}{r_{00j}} \\\\ \\beta_{10j} = \\color{darkred}{\\gamma_{100}} + \\color{darkgreen}{r_{10j}} \\\\ (u_{0ij}, u_{1ij}) \\sim N(\\bf{0}, \\Sigma) \\\\ (r_{00j}, r_{10j}) \\sim N(\\bf{0}, \\tau) \\] Outcome deoends on level 1 things, then how level 2 things depend on level 1 things, then how level 3 things depend on level 2 things. (last two lines of equation above are not correct) \\(\\beta\\) is about specific schools (level 2), while \\(\\gamma\\) is across the whole population (level 3). R syntax: mod11 &lt;- lmer(read ~ 1 + time + (1 + time | id) + (1 + time | schid), data = dat) ## same as mod11 &lt;- lmer(read ~ 1 + time + (1 + time | id/schid), data = dat) ## same as mod11 &lt;- lmer(read ~ 1 + time + (1 + time | id:schid) + (1 + time | schid), data = dat) Reduced form (substitute the \\(\\pi\\)’s): \\[ Y_{ijt} = \\pi_{0ij} + \\pi_{1ij}time_{ijt} + \\epsilon_{ijt} \\\\ = (\\beta_{00j} + u_{0ij}) + (\\beta_{10j} + u_{1ij})time_{ijt} + \\epsilon_{ijt} \\\\ = \\beta_{00j} + \\beta_{10j}time_{ijt} + u_{0ij} + u_{1ij} \\epsilon_{ijt} \\\\ = (\\gamma_{000} + r_{00j}) + (\\gamma_{100} + r_{10j}) + u_{0ij} + u_{1ij} time_{ijt} + \\epsilon_{ijt} \\\\ = \\color{darkred}{\\gamma_{000} + \\gamma_{100}time_{ijt}} + \\color{darkgreen}{r_{00j} + r_{10j}time_{ijt} + u_{0ij} + u_{1ij}time_{ijt} + \\epsilon_{ijt}} \\] Offset due to schools are the \\(r\\)’s. Offset due to students are the \\(u\\)’s. The \\(\\epsilon_{ijt}\\) is the same sort of error as in single-level OLS (i.e., measurement error). The random effect ‘stack’ on top of each other. Fixed effect population averages are in \\(\\color{darkred}{darkred}\\), while residuals are in \\(\\color{darkgreen}{darkgreen}\\). You could have the higher level (level 3 here) be fixed effects only — so if you only had 5 schools, this could be a 2-level mixed model for students over time with fixed effects for school. Level 2 covariates Including student ELL status (time-invariant) in the two-level form: \\[ read_{ijt} = \\pi_{0ij} + \\pi_{1ij}time_{ijt} + \\color{darkgreen}{\\epsilon_{ijt}} \\\\ \\color{darkgreen}{\\epsilon_{ijt}} \\sim N(0, \\sigma^2) \\\\ \\pi_{0ij} = \\beta_{00j} + \\beta_{01j}ELL_{ij} + \\color{darkgreen}{u_{0ij}} \\\\ \\pi_{1ij} = \\beta_{10j} + \\beta_{11j}ELL_{ij} + \\color{darkgreen}{u_{1ij}} \\\\ \\color{grey}{\\textrm{average school reading score:}} \\quad \\beta_{00j} = \\color{darkred}{\\gamma_{000}} + \\color{darkgreen}{r_{00j}} \\\\ \\color{grey}{\\textrm{school-specific ELL initial gap:}} \\quad \\beta_{01j} = \\color{darkred}{\\gamma_{010}} + \\color{darkgreen}{r_{01j}} \\\\ \\color{grey}{\\textrm{school avarge growth rate:}} \\quad \\beta_{10j} = \\color{darkred}{\\gamma_{100}} + \\color{darkgreen}{r_{10j}} \\\\ \\color{grey}{\\textrm{school specific ELL/non-ELL growth rate:}} \\quad \\beta_{11j} = \\color{darkred}{\\gamma_{110}} + \\color{darkgreen}{r_{11j}} \\\\ \\] We have four 3rd-level equations. We now have a \\(4 \\times 4\\) matrix for the random effects. Reduced form: \\[ read_{ijt}= \\color{darkred}{\\gamma_{000} + \\gamma_{010}ELL_{ij} + \\gamma_{100}time_{ijt} + \\gamma_{110}ELL_{ij}time_{ijt}} + \\color{darkgreen}{r_{00j} + r_{01j}ELL_{ij} + r_{10j}time_{ijt} + r_{11j}time_{ijt}ELL_{ij} + u_{0ij} + u_{1ij}time_{ijt} + \\epsilon_{ijt}} \\] R model syntax: mod11 &lt;- lmer(read ~ 1 + time * ell + (1 + time | id) + (1 + time * ell | schid), data = dat) Level 3 covariates How does poverty interact with growth (school level) Including school poverty variable in the two-level form: SEE PHOTO!!!! the below equation is not correct, just the same as above. \\[ read_{ijt} = \\pi_{0ij} + \\pi_{1ij}time_{ijt} + \\color{darkgreen}{\\epsilon_{ijt}} \\\\ \\color{darkgreen}{\\epsilon_{ijt}} \\sim N(0, \\sigma^2) \\\\ \\pi_{0ij} = \\beta_{00j} + \\beta_{01j}ELL_{ij} + \\color{darkgreen}{u_{0ij}} \\\\ \\pi_{1ij} = \\beta_{10j} + \\beta_{11j}ELL_{ij} + \\color{darkgreen}{u_{1ij}} \\\\ \\color{grey}{\\textrm{average school reading score:}} \\quad \\beta_{00j} = \\color{darkred}{\\gamma_{000}} + \\color{darkgreen}{r_{00j}} \\\\ \\color{grey}{\\textrm{school-specific ELL initial gap:}} \\quad \\beta_{01j} = \\color{darkred}{\\gamma_{010}} + \\color{darkgreen}{r_{01j}} \\\\ \\color{grey}{\\textrm{school avarge growth rate:}} \\quad \\beta_{10j} = \\color{darkred}{\\gamma_{100}} + \\color{darkgreen}{r_{10j}} \\\\ \\color{grey}{\\textrm{school specific ELL/non-ELL growth rate:}} \\quad \\beta_{11j} = \\color{darkred}{\\gamma_{110}} + \\color{darkgreen}{r_{11j}} \\\\ \\] R model syntax (with 3-way interaction): mod12 &lt;- lmer(read ~ 1 + time * ell * poverty_school + (1 + time | id) + (1 + time * ell | schid), data = dat) Split initial ability (intercepts) and growth rate (time) equations: \\[ read_{ijt} = (\\gamma_{000} + \\gamma_{010}ELL_{ij} + \\gamma_{001}Poverty_{j} + \\gamma_{011}ELL_{ij}Poverty_{j}) + \\\\ (\\gamma_{100} + \\gamma_{110}ELL_{ij} + \\gamma_{101}Poverty + \\gamma_{111}ELL_{ij}Poverty_{j}) * time_{ijt} \\] Lecture 4.2 (A) Crossed Random Effects Models Cross-classified models arise when we have multiple nesting structures (e.g., when each observation can be classified into multiple different level-2 units). For example, students are nested in both schools and neighborhoods. Lecture 4.2 (B) AIC and Model Selection / Building (model search) Picking from a bunch of different models that are not nested. R&amp;B ch 9, 252-276. Options for model selection (statistical tools): Likelihood Ratio Tests Cannot do likelihood ratio testing on non-nested models. need to fit the models to exactly the same data Model inspection / evaluation AIC / BIC / etc. penalizes more complicated models can compare non-nested models can compare whole families of models need to fit the models to exactly the same data Complexity versus model fit: more parameters means more flexible, but the model is more complicated. AIC: a measure of the relative quality of statistical models: \\[ AIC = -2(LL) + 2k \\] Where \\(k\\) is the number of parameters and \\(LL\\) is the log-likelihood. BIC &amp; DIC: measures of the relative quality of statistical models: \\[ BIC = -2(LL) + log(n)k \\\\ DIC = -2(LL) + k_D \\] Sample size for BIC? Should it be number of units at level 1 — super conservative (does not take into account the nested structure of data)? Or number of level 2 units — less conservative? Information criteria should get the gross ordering of good vs. bad models right. Then use LRTs for specific terms between the good models. Always plot the data. Lecture 4.3 Randomized Experiments Custer randomized experiments (each school gets treated or not). Multisite randomized experiments (a bunch of schools, where a fraction of the students in each get treated). Each school is a mini-experiment, and you can see how these experiments differ across schools. Randomized experiments: The experimenter obtains a collection of units, then randomized units into treatment and control. This makes, for typical randomizations, the treatment group and the control group more or less the same. Now, if we see any differences in outcome, we can ascribe this to the treatment itself. Potential outcomes The Neyman-Rubin potential outcomes framework: Assume treatment assignment for any unit has no impact on any other unit (SUTVA). Each unit has two outcomes; \\(y(1)\\): what happens when you treat it \\(y(0)\\): what happens when you do not The treatment effect for unit \\(i\\) is then \\(\\tau = y(1) - y(0)\\). We observe either \\(y(1)\\) or \\(y(0)\\) depending on whether we treat unit \\(i\\) or not. The potential outcomes are fixed. The randomness comes from how treatment is assigned. How treatment is assigned is called the assignment mechanism. In a potential outcomes framework, randomness is due to assignment, the units can be considered fixed. The key idea is that any individual has two outcomes, only one of which we see. Cluster Randomized Trials Must take clustering into account when modeling these designs. What are we estimating? Average treatment effect of sites Average treatment effect of people \\[ Y_{ij} = \\beta_j + r_{ij} \\\\ \\beta_j = \\gamma_0 + \\gamma_1T_j + u_j \\\\ u_j \\sim N(0, \\sigma^2_u) \\] Treatment, \\(T_j\\), is a level-2 variable. We cannot separate variation in treatment impact and variation in clusters. We might reasonably worry about the 2nd-level variance term: we could let it vary by treatment status with an extended model with different variances for the treatment groups. mod14 &lt;- lmer(year ~ 1 + T + (1 | schid), data = dat) How many units? If the clusters are radically different and the units within a cluster very much the same, then we really have only \\(j\\) units in our experiment. If the clusters are the samne, and individuals within cluster basically independent, then we have closer to \\(nJ\\) units. Moral: cluster-randomization can be a much smaller experiment than you think. Rough estimate of uncertainty: \\[ \\hat{\\gamma_1} = \\hat{Y_T} - \\hat{Y_C} \\\\ Var(\\hat{\\gamma_1}) = \\frac{1}{J} \\left( 4\\sigma^2_u + \\frac{\\sigma^2}{n} \\right) \\] Cost of data collection: \\[ Cost = J(C_{1n} + C_2) \\] You can do power and optimal cost/design calculations for specific scenarios but they may not generalize. Could instead simulate to model more complex and authentic scenarios. ICC strongly affects power: as ICC gets bigger you need more clusters (more clusters rather than a few big clusters). Can get ICC from pilot studies or previous research to use in power analysis. Multisite Experiments Each site is a mini-experiment, but they are related. Research questions: What is the average impact across sites? What is the variation in impacts across sites? What is the impact for a specific site? (Harder - comes from empirical Bayes estimates) Compared to cluster randomization: here we get treatment info. for each site. Cluster-randomization gives no treatment info. for any site. This means we have more power, because we can assess the site impact as well as the treatment impact. Model - two-level notation: \\[ Y_{ij} = \\beta_{0j} + \\beta_{1j}T_{ij} + \\color{darkgreen}{r_{ij}} \\\\ \\color{darkgreen}{r_{ij}} \\sim N(0, \\sigma^2) \\\\ \\beta_{0j} = \\color{darkred}{\\gamma_{00}} + \\color{darkgreen}{u_{0j}} \\\\ \\beta_{1j} = \\color{darkred}{\\gamma_{10}} + \\color{darkgreen}{u_{1j}} \\\\ \\left( \\frac{u_{0j}}{u_{1j}} \\right) \\sim N \\left[\\frac{0}{0} ? \\right] \\] "],
["05_Generalized_linear_models.html", "Generalized linear models Lecture 5.1 Lecture 5.2 Lecture 5.3 Lecture 5.4", " Generalized linear models Lecture 5.1 Generalized Linear Models Poisson models Case study: police stops by ethnic groups. Is the rate of police stops higher or lower for certain groups and precincts than we would predict given amount of crime. Variables are: police prencint, ethnicity, number of past arrests, number of stop and frisk events, and population. The unit of analysis is the police precinct level over a certain period of time. Estimation strategy: We can watch any given precinct The number of stops are count data Goal: is the number of stops relatively larger given crime levels? Want to estimate the rate: the numbner of stop and frisk per unit time. \\[ Y_i \\sim Poisson(\\theta_i) \\] For each unit, at any given moment, the chance of seeing an event is the same as at any other moment. This chance is the rate we’re trying to estimate. The rate is the expected number of observations per unit time. With high rates (&gt;= 15), you can probably get away with a Gaussian model, though this would be a model with additive effects (unless the response is logged), rather than the multiplicative effects provided my Poisson models. The mean and variance in Poisson are tied together. Poisson distributions are indexed by a single parameter \\(\\theta\\). We model the connection between our observed outcome and a rate parameter: \\[ Y_i \\sim Poisson(\\theta_i) \\] And then we model our rate parameter as a function of our covariates: \\[ \\theta_i = exp(\\eta) \\\\ \\color{grey}{\\textrm{The linear predictor:}} \\quad \\eta = X_i\\beta \\] Say we have: \\[ Y_i = Poisson(exp(2.8 + 0.012X_{i1} - 0.20X_{i2})) \\] \\[ \\theta_i = exp(2.8 + 0.012X_{i1} - 0.20X_{i2}) \\\\ = e^{2.8} \\times e^{0.012X_{i1}} \\times e^{-0.20X_{i2}} \\\\ \\color{grey}{\\textrm{Impact of inductrial zone is a scaling on average (rate):}} \\quad e^{-0.20\\times1} = 0.82 \\] Need to exponentiate the coefficents before interpreting them as multiplicative effects. Exposure \\(u_i\\) is multplied by rate: \\[ Y_i \\sim Poisson(u_i\\theta_i) \\] Offset: like a covariate where the coefficient is fixed at one: \\[ \\hat{Y_i} = u_i\\theta_i = u_i exp(X_i\\beta) = exp(log(u_i)) \\times exp(X_i\\beta) = exp[log(u_i) + X_i\\beta] \\\\ \\color{grey}{\\textrm{The offset:}} \\quad log(u_i) \\] mod13 &lt;- glm(stops ~ 1, family = poisson(link = &quot;log&quot;), offset = log(past.arrests), data = stops) The number of stops, on average, per unit time (so, about half of one stop per unit time). \\[ e^{-0.59} = 0.55 \\] mod13 &lt;- glm(stops ~ 1 + ethnicity, family = poisson(link = &quot;log&quot;), offset = log(past.arrests), data = stops) \\[ stops_i = Poisson(u_i\\theta_i) \\\\ \\theta_i = exp[ \\beta_0 + \\beta_1Hispanic_i + \\beta_2White_i + log(u_i)] \\] where \\(log(u_i)\\) is the log of prior arrests. Model fitting. Compare difference in likelihoods: \\[ D \\sim \\chi^2_m \\\\ E[D] = m \\] Add precinct (this is basically a fixed effects model): mod13 &lt;- glm(stops ~ 1 + ethnicity + precinct, family = poisson(link = &quot;log&quot;), offset = log(past.arrests), data = stops) Overdispersion The poisson model says variance depends on rate. Can use standardized residuals to detect overdispersion. Only 5% of standardized residuals should be outside of \\(\\pm 2\\) — if there is more than that, then there is overdispersion. Simulation: N &lt;- 200 X &lt;- log(runif(N, 0.1, 3)) exposure &lt;- runif(N, 0.5, 2) rate &lt;- 1 + 2 * X Y &lt;- rpois(N, lambda = exposure * exp(rate)) mod14 &lt;- glm(Y ~ X, family = poisson, offset = log(exposure), data = df) yhat &lt;- predict(mod14, type = &quot;response&quot;) z &lt;- (yhat / ?) ### ?????? plot() So, we ask whether our standardized residuals are standard normal. Poisson model has its own heteroscasticity built it, but there can be more heteroscasticity than it can deal with. Can fix overdispersion using an overdispered Poisson model: a quasipoisson or negative binomial model. These both have extra parameters to allow extra scatter around what you fit. Anatomy of a Generalized Linear Model Data Predictor matrix Linear predictor Link function Lecture 5.2 Multilevel Logistic Regression R&amp;B Ch. 10 Thailand Retention Data: students are in schools and are either retained (held back) or not. \\[ Y_{ij} \\sim F(\\mu_{ij}, \\upsilon) \\\\ E[Y_{ij}] = \\mu_{ij} \\] \\[ \\eta_{ij} = g(\\mu_{ij}) \\quad \\textrm{with} \\quad Y_{ij} \\sim F(\\mu_{ij}, \\upsilon) \\] where \\(eta_{ij}\\) is the linear predictor. \\[ \\eta_{ij} = \\beta_{0j} + \\beta_{1j}X_{1ij} + \\beta_{2j}X_{2ij} \\] Note the lack of the residual term - that’s extra randomness that happens outside of this equation of the structural component of the model. \\[ \\eta_{ij} = \\beta_{0j} + \\beta_{1j}X_{1ij} + \\beta_{2j}X_{2ij} \\\\ p_{ij} = logit^{-1}(\\eta_{ij}) \\] Take out the random slopes for simplicity (the \\(j\\) subscripts on the \\(\\beta_1\\) and \\(\\beta_2\\)), so this is a random intercept model. \\[ \\eta_{ij} = \\beta_{0j} + \\beta_{1}X_{1ij} + \\beta_{2}X_{2ij} \\] Level 2 is still a vanilla linear model, because we’re modeling the level-1 coefficients, which are continuous: \\[ \\beta_{qj} = \\gamma_{q0} + \\gamma_{q1}W_{ij} + ... u_{qi} \\] mod15 &lt;- glmer(Repeat ~ 1 + (1 | schoolID), data = dat, family = binomial(link = &quot;logit&quot;)) The thing that gets us from the linear predictor to what we expect = link function. The thing that gets us from what we expect to what we see = family distribution. KEY POINT: Typical is not the same as population average due to non-linearlity! ICC - not so useful: ICC is the ratio of level-2 variance to total variance But different schools have different kids, and so different variances due to binomial There is no natural ICC ratio here Instead draw pictures and show people how much schools vary. mod15 &lt;- glmer(Repeat ~ 1 + sex + pped + msesc(1 | schoolID), data = dat, family = binomial(link = &quot;logit&quot;)) dat$eta_hat &lt;- predict(mod15) # link scale dat$eta_hat &lt;- predict(mod15, type = &quot;response&quot;) # response scale Population average versus individual school Answering the question: what is the association between pped and response at a specific school. Lecture 5.3 Longitudinal Data with a Binary Outcome Reading: R-H &amp; S Ch. 10 (in particular, 10.3 - 10.13) Toenail infection data: subjects randomly assigned to two antifungal treatments (RCT). Outcome is the separation of toenail from toebed. Did the treatment work? (inference — are the two groups different from each other?) Did the treatment work well? (measure the relative speed of how these rates change) Looking at missingness Look at the pattern of missingness: MAR — missing at random. The missingness can be deduced from the remaining data. This plays well with MLM. Looking at outcome data Autocorrelation is an issue. Could think of it as a growth curve on a latent probability of toenail detachment. Visualizations Aggregating the data for visualization: look at proportions for each visit by treatment combo. But people who got better faster might have left the study. Issues: 1) differential dropout, 2) need to perform inference Marginal models: population average effects (no random effects) mod16 &lt;- glm(outcome ~ treatment * month, family = binomial(link = &quot;logit&quot;), data = toes) \\[ prob = \\frac{odds}{1 + odds} \\\\ prob = \\frac{e^\\beta}{1 + e^\\beta} \\\\ prob = \\frac{1}{1 + e^{-\\beta}} \\] Intercept: $$ logit(p) = -0.56 \\ p = logit^{-1}(-0.56) = = 0.36 \\[ Probability of detachment at 3 months for control group: \\] logit(p_{3mc}) = -0.56 + 3(-0.17) \\ p_{3mc} = 0.255 $$ Probability of detachment at 3 months for treatment group: \\[ logit(p_{3mt}) = -0.56 + 3(-0.17) + 3(-0.07) \\\\ p_{3mt} = 0.218 \\] Two general strategies population focus (adjust SEs with clustered SEs): marginal models individual focus (for a specific person, what’s the advantage of treatment): MLM Latent growth models \\(i\\) is time, \\(j\\) is individual. Random intercept model (two level form): \\[ Y_{ij} \\sim Binomial(1, \\pi_{ij}) \\\\ logit(\\pi_{ij}) = \\beta_{0j} + \\beta_{1j}Time_{ij} \\\\ \\beta_{0j} + \\gamma_{00} + \\gamma_{01}Z_{j} + u_j \\\\ \\beta_{1j} + \\gamma_{10} + \\gamma_{11}Z_{j} \\] Reduced form: \\[ Y_{ij} \\sim Binomial(1, \\pi_{ij}) = Bern(\\pi_{ij}) \\\\ logit(\\pi_{ij}) = \\gamma_{00} + \\gamma_{01}Z_{j} + \\gamma_{1j}Time_{ij} + \\gamma_{1j}Z_jTime_{ij} + u_j \\\\ u_j \\sim N(0, \\tau_{00}) \\] mod17 &lt;- glmer(outcome ~ treatment * month + (1 | patient), family = binomial(link = &quot;logit&quot;), data = toes) With logistic models, random effects make fixed effects conditional effects: The individual effect is much more extreme. At the population level, the individual level variation reduces the treatment effect. Lecture 5.4 Multilevel Generalized Linear Models Reading: Gelman &amp; Hill section 15.1 Multilevel Poisson — stop and frisk data The poisson fixed effects made our comparisons within precinct comparisons (i.e., we asked, in a given place, was there imbalance?). But, we can make precinct a random effect — why? 1) to estimate how much precincts vary, and 2) obtain better estimates of individual precincts via partial pooling (discern which precincts are more or less “active”). Multilevel model: mod18 &lt;- glmer(stops ~ 1 + ethnicity + (1 | precinct), offset = log(past.arrests), family = poisson(link = &quot;log&quot;), data = stops) Over-dispersion in single-level count data quasipoisson negative binomial add a random effect for each observation (like adding a residual back in). This allows some cases to have more events than expected and some less, given exposure and observed covariates. This works because we can think of the individual cases as, in some sense, multiple observations (the individual counted events). \\[ y_i = Poisson(u_ie^{X_i\\beta}) \\\\ y_i = Poisson(u_ie^{X_i\\beta + \\epsilon}) \\\\ \\epsilon \\sim N(0, \\sigma^2) \\] Observation level random effects to account for overdispersion - even in a none multilevel context. This is an alternative to a single level quasipoisson: mod19 &lt;- glmer(stops ~ 1 + ethnicity + precinct + (1 | id), offset = log(past.arrests), family = poisson(link = &quot;log&quot;), data = stops) Over-dispersion in multi-level count data Full multilevel model accounting for overdispersion. The uncertainty estimates (standard errors) will increase in size: mod20 &lt;- glmer(stops ~ 1 + ethnicity + (1 | precinct) + (1 | id), offset = log(past.arrests), family = poisson(link = &quot;log&quot;), data = stops) Subgroup analysis Two options: Divide data up into groups (results in completely unpooled estimates for each subgroup) Full modeling (include interactions for the subgroups) Model sensitivity checks Did our results depend of how we divided precincts? How much would things change if we tweaked our analysis? We don’t want to think that our findings are the result of our estimation strategy, but rather reflect the underlying data. "],
["06_Sandwich_estimator.html", "Sandwich estimator Lecture 6.1 Lecture 6.2 Lecture 6.3", " Sandwich estimator Lecture 6.1 OLS and the “Sandwich” Standard Error A robust Haiku T-stat looks too good. Use robust standard errors. Significance gone. The standard error and standard error estimate is a function of the randomness in the residuals only — this is the only random part of an OLS model. Core idea: use the residuals to get a rough (bad) estimate of the variability of the individual observations, and average to get good overall performance. Canonical regression formula for OLS: \\[ Y = \\bf{X\\beta} + \\epsilon \\] where \\(\\bf{\\beta}\\) is a p-vector of coefficients to be estimated, \\(\\bf{X}\\) is a matrix where there is a column of 1s as the first “covariate” and beta will have an initial coefficient for the intercept corresponding to this column of 1s, \\(Y\\) is an n column of outcomes, and \\(\\epsilon\\) is an n vector of residuals. We can think of a regression (with fixed y) as a single matrix multiply. This is useful when thinking about how the residual vector, \\(\\epsilon = (\\epsilon_1, ..., \\epsilon_n)\\), is random. Inverse = division, so the inverse of 5 would be 1/5, because if you multiply 1/5 by 5, you get 1 - which is the identity. HC2 is best? Maybe HC3. Lecture 6.2 Cluster Robust Standard Errors Building on heteroskedastic robust standard errors (the sandwich estimator) from last lecture… Cluster robust standard errors: We use classic OLS to get population trends. Then, if we believe clusters are themselves an independent sample, we can use residuals to get very bad estimates of residual structure for each cluster. We then average to get decent overall estimates. This is a close sister to the sandwich, sharing the same intuition. All of this is only for the fixed effects. Big n by n matrix for residuals, which contains bad but unbiased estimates, then average over these to get better estimates. Also, a small p by p matrix for parameters. With clustered data, the observations within a cluster are correlated (i.e., the residuals for people within a cluster are similar). So, our residual covariance matrix is NOT a diagonal matrix. This leads to a block diagonal matrix. So, conditional on the overall trends (i.e., the fixed effects), we get a block diagonal matrix for the residuals. Our estimate of \\(\\hat{\\beta}\\) is going to be the sum of a bunch of \\(\\hat{\\beta}\\) for each cluster group - because we are essentially fitting separate regressions to each group and then aggregating the coefficients (while weighting them). The random intercept model says that the off-diagonals in the VCV matrix are the same, but when using cluster robust standard errors we say that we don’t know what the off-diagonals are. When do we get big standard errors on our fixed effects? We get large variances compared to OLS when: Covariates vary mostly across cluster rather than within cluster (note how a group level covariate only varies cross cluster!). Errors within cluster are correlated so the omegas are non-zer (generally positive). \\(N_g\\) is large (many units inside a cluster). Within-cluster regressor and error correlations are the same sign (which is typical). Take away messages: There can be a great loss of efficiency in OLS estimation if errors are correlated within cluster. (“More observations in the cluster doesn’t tell you much that is new”) But sometimes these methods give you smaller errors than you would expect Rule of thumb — specify the clusters at the highest level. If you don’t, then you’ll be ignore some dependence between your units. Bell reading - fixed effects regression with cluster robust standard errors versus MLM. Lecture 6.3 Fitting models with complex residual error structure Dataset: national youth survey. We have longitudinal data measured at specific waves. We can fit a linear growth model, but we may worry that our within-student residuals are not iid (i.e., adjacent residuals tend to be similar - have the same sign). Two methods: 1. overall residual \\(u_{ti}\\) (using cluster robust standard errors) 2. within-student residuals \\(r_{0i}\\) \\(r_{1i}\\) (using MLM) Method 1 Modeling: \\[ u_{ti} = r_i + \\epsilon_{ti}, t = 1,...,5 \\] Method 2 R&amp;B page 190 Compound symmetry = distribution of the \\(u\\) around the black line. AR1 random slope - produces heteroskedastic residuals, since the slopes fan out over time random slopes with heteroskedasticity random slopes with unstructured "],
["07_Bayesian_models.html", "Bayesian models Lecture ST.2", " Bayesian models Lecture ST.2 Our possible friend Stan or fitting models with a very flexible Bayesian modeling framework prob(something given evidence) = prob(evidence given something) prob(something) / prob(evidence) prob(A | B) = prob(B | A) prob(A) / prob(B) prob(truth | data) = prob(data | truth) prob(truth) / prob(data) prob(A) = prior prob(B | A) = likelihood prob(A | B) = posterior prob(B) = data (just a scaling constant - does not involve the parameters at all) The cartoon guide to statistics. Archery example. Credible interval and confidence intervals converge asymptotically. MCMC Monte Carlo = simulation Markov chain = how the simulation works Stan = a big simulator Shrinkage: priors shrink the ML estimate towards the prior belief. Full Bayes tend to shrink less than Empirical Bayes (unless there’s a strong prior) No empirical Bayes step needed in a Bayesian MLM - you just get individual random effect parameters directly from the model, rather than using the model to predict them. "]
]
