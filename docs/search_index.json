[
["index.html", "Linear Mixed Models Introduction Table of Contents Authors and Sources", " Linear Mixed Models August 2020 Introduction Reports in Rmarkdown: https://www.stat.cmu.edu/~cshalizi/rmarkdown/ Math in Rmd: https://www.calvin.edu/~rpruim/courses/s341/S17/from-class/MathinRmd.html Rmd example: http://www.math.mcgill.ca/yyang/regression/RMarkdown/example.html Table of Contents Here, we outline how the guide is organized into parts. First, we… Second, we… Lastly, we… Here we provide an outside link to important content which puts some useful information for this tutorial/workshop at our fingertips. Here we specify where people can provide feedback! Please email help@iq.harvard.edu Authors and Sources Here we acknowledge a few people who helped make this tutorial/workshop possible. We also reference any sources that material was taken from. ## Loading required package: Matrix "],
["fixed-effects-models.html", "Fixed effects models Lecture 1.2 Lecture 2.1", " Fixed effects models Lecture 1.2 \\[ MA_i = \\beta_0 + \\beta_1*SES + \\beta_2*I(id=2)... \\beta_k*I(id=k) \\] School level fixed effects — allow each school to differ. They will raise or lower the slope of SES depending on the school. The indicators adjust for school-level differences — called fixed effects. This “completely pools” the SES relationship — it’s the same for each school. THIS IS INCORRECT — FIXED EFFECTS RESULT IN NO POOLING Drop the intercept when using fixed effects? But this would force SES through the origin, no? Have NOT pooled the intercept, but HAVE completely pooled the slope. Models impose structure - if the structure is not true, our model estimates can be wrong. fit1 &lt;- lm(math ~ ses * id - 1 - ses, data = hsb) # gives you k slopes and intercepts, where k is the number of schools. Point estimates the same as fitting each school separately. But, when fitted together, you get one estimate for the residual variance, but when fitted separately, you get different residual variances for each school. Sorting out the measurement error versus the structure - are the slopes really different or do they just look different? Inference - separating what is real from what is random. dplyr Data pipeline - data gets handed to the next thing in line, then the output of that gets handed to the next thing in line. Overdispersion: Dots stacked up. Jitter the dots. Each dot is average of some school. More variance you have across the dots, the more overdispersion you have. How much modeling flexibility is the right amount? Need a model flexible enough to capture the main structure of the data, but not so flexible that they’re hard to estimate. Lecture 2.1 Aggregation is unsatisfying: underpowered biased heteroscedastic Multilevel models are really lots of models tied together. classic estimate of average for each county Single county \\(j\\) \\(n_j\\) houses \\(Y_{ij}, Y_ni\\) -&gt; \\(stdev(Y_i... Y_nj) = S_j\\) -&gt; \\(\\hat{Y}_j\\) -&gt; \\(\\hat{SE} = \\frac{S_j}{sqrt(n_j)}\\) Fixed effects regression Take average value of radon for each county then add value for each house - this is fixed effects regression. \\[ house_i = \\alpha_j[i] + \\epsilon_i \\] Fixed effects assumes homoscedasticity of the error around the counties - county level variances are the same - with this assumption, we can estimate just one error term for the model. Unlike when you model counties in separate regression models - where you have a separate error term for each model and therefore allow the variance within eaxch county to be different (like GLS). Shrink estimates towards a common mean. House \\(i\\) in county \\(j[i]\\). \\[ y_i = \\alpha_j[i] + \\epsilon_i \\\\ \\epsilon_i ~ N(0, \\sigma^2_\\alpha) \\\\ \\alpha_j ~ N(\\mu, \\sigma^2_\\alpha) %% &quot;soft constraint&quot;: this ties the intercepts together \\] \\(\\alpha_j\\) are the county means. \\(\\mu\\) is the grand mean of the county means (NOT the same as the mean of all the houses). \\(\\sigma^2_\\alpha\\) is the variance of the county means. Shrinkage - a weighted average of the mean for the county and the grand mean of the counties. Shrinkage = empirical Bayes estimate. Tend to be underdispersed, compared to the overdispered fixed effects estimates. Bias-variance trade off - can introduce some bias into the estimates in return for removing a lot of variance. This will result in better estimates overall. Level 1 predictors Basement floor indicator. coef(model)$county # get the empirical Bayes estimates for each county "],
["mixed-effects-models.html", "Mixed effects models Lecture 2.3 Lecture 2.4 Lecture 2.5 Lecture 2.6", " Mixed effects models Lecture 2.3 gender gap and math achievement Two level notation \\[ math_{ij} = \\beta_{0j} + \\beta_1*female_{ij} + \\epsilon_{ij} \\\\ \\beta_{0j} = \\mu + U_{0j} \\] where \\(\\epsilon \\sim N(0, \\sigma^2)\\) and \\(U_{0j} \\sim N(0, \\sigma^2)\\) Single level notation \\[ math_{ij} = \\mu + \\beta1*female_{ij} + U_{0j} + \\epsilon_{ij} \\] where \\(U_{0j}\\) is the random intercept. mod1 &lt;- lmer(math ~ 1 + female + (1 | id), data = hsb) summary(mod1) ## Linear mixed model fit by REML [&#39;lmerMod&#39;] ## Formula: math ~ 1 + female + (1 | id) ## Data: hsb ## ## REML criterion at convergence: 47056 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -3.1956 -0.7506 0.0379 0.7704 2.6211 ## ## Random effects: ## Groups Name Variance Std.Dev. ## id (Intercept) 8.169 2.858 ## Residual 38.850 6.233 ## Number of obs: 7185, groups: id, 160 ## ## Fixed effects: ## Estimate Std. Error t value ## (Intercept) 13.3449 0.2547 52.400 ## female -1.3590 0.1714 -7.927 ## ## Correlation of Fixed Effects: ## (Intr) ## female -0.350 # Intercept is \\mu, \\beta_1 is female, 1 in parentheses is the random intercept (U_{0j}) Extend to Catholic schools (sector variable): Two level notation \\[ math_{ij} = \\beta_{0j} + \\beta_1*female_{ij} + \\epsilon_{ij} \\\\ %% level 1, where \\epsilon \\sim N(0, \\sigma^2) \\beta_{0j} = \\mu + U_{0j} + \\gamma_{01}*sector_j \\\\ %% level 2, where U_{0j} \\sim N(0, \\sigma^2) \\beta_{1j} = \\gamma_{10} + \\gamma_{11}*sector_j %% level 2, add sector at level 2 \\] First subscript tells us which beta, Second subscript tells us which which piece inside the equation - so sequentially from 0 to n for each term. Single level notation \\[ math_{ij} = \\beta_{0j} + \\beta_1*female_{ij} + \\epsilon_{ij} \\\\ %% level 1 = (\\gamma_{00} + \\gamma_{01}*sector_j + U_{0j}) + (\\gamma_{10} + \\gamma_{11}*sector_j) + female_j + \\epsilon_{ij} \\\\ = \\gamma_{00} + \\gamma_{01}*sector_j + U_{0j} + \\gamma_{10}*female + \\gamma_{11}*sectorFemale_j + \\epsilon_{ij} \\] The coefficient for the interaction is \\(\\gamma_{11}\\). mod2 &lt;- lmer(math ~ 1 + sector + female + sector : female + (1 | id ), data = hsb) summary(mod2) ## Linear mixed model fit by REML [&#39;lmerMod&#39;] ## Formula: math ~ 1 + sector + female + sector:female + (1 | id) ## Data: hsb ## ## REML criterion at convergence: 47017.2 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -3.15363 -0.75077 0.03403 0.76707 2.61443 ## ## Random effects: ## Groups Name Variance Std.Dev. ## id (Intercept) 6.286 2.507 ## Residual 38.849 6.233 ## Number of obs: 7185, groups: id, 160 ## ## Fixed effects: ## Estimate Std. Error t value ## (Intercept) 12.1714 0.3056 39.831 ## sectorcatholic 2.6177 0.4667 5.608 ## female -1.4818 0.2092 -7.085 ## sectorcatholic:female 0.3338 0.3618 0.922 ## ## Correlation of Fixed Effects: ## (Intr) sctrct female ## sectorcthlc -0.655 ## female -0.360 0.235 ## sctrcthlc:f 0.208 -0.402 -0.578 # Intercept is \\mu, \\beta_1 is female, 1 in parentheses is the random intercept (U_{0j}) Covary - having an unusual intercept can be predictive of having an unsual slope - knowing one tells you about the other. Intercepts and slopes can covary - pulled from a multivariate normal distribution. Intercept and slope are tied together. Covariance = correlation on scale of original variables Correlation = unitless mod3 &lt;- lmer(math ~ 1 + ses + (1 + ses | id ), data = hsb) summary(mod3) ## Linear mixed model fit by REML [&#39;lmerMod&#39;] ## Formula: math ~ 1 + ses + (1 + ses | id) ## Data: hsb ## ## REML criterion at convergence: 46640.4 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -3.12272 -0.73046 0.02144 0.75610 2.94356 ## ## Random effects: ## Groups Name Variance Std.Dev. Corr ## id (Intercept) 4.8287 2.1974 ## ses 0.4129 0.6426 -0.11 ## Residual 36.8301 6.0688 ## Number of obs: 7185, groups: id, 160 ## ## Fixed effects: ## Estimate Std. Error t value ## (Intercept) 12.6650 0.1898 66.71 ## ses 2.3938 0.1181 20.27 ## ## Correlation of Fixed Effects: ## (Intr) ## ses -0.045 # random intercept and slope for ses # to get covariance, you can multiply the correlation between intercept and slope with the intercept variance and then the slope variance Empirical Bayes estimates over-shrink. They provide too much pooling. Can simulate from the model to mitigate this. So, generate random schools from the model to simulate more accurately the variation. Lecture 2.4 Modeling assumptions Assumptions are less important for describing trends in data, rather than estimating causal effects. Level 1 exogeneity: \\(r_{ij} \\overset{i.i.d.}{\\sim} N(0, \\sigma^2)\\) &lt;– classic OLS assumptions –&gt; Level 2 exogeneity: \\(Cov(X_{qij}, r_{ij} = 0\\) Level 1 homoskedasticity: \\(u_j = (u_{0j}, ..., u_{Qj})&#39; \\overset{i.i.d}{\\sim} N()\\) Level 2 homoskedasticity: Uncorrelation of residuals: \\(Cov(r_{ij}, u_{qj}) = 0\\) &lt;– cross level assumptions –&gt; Uncorrelation of random effects: $Cov(X_{qij}, $ Uncorrelation of residuals with random effects: Normal distribution of random effects (less important): mod4 &lt;- lmer(math ~ 1 + female + sector + ses + sector : ses + meanses + (1 + ses | id), data = hsb) summary(mod4) ## Linear mixed model fit by REML [&#39;lmerMod&#39;] ## Formula: math ~ 1 + female + sector + ses + sector:ses + meanses + (1 + ## ses | id) ## Data: hsb ## ## REML criterion at convergence: 46462.9 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -3.08893 -0.73219 0.02407 0.76266 2.92613 ## ## Random effects: ## Groups Name Variance Std.Dev. Corr ## id (Intercept) 2.11395 1.454 ## ses 0.03096 0.176 0.65 ## Residual 36.60081 6.050 ## Number of obs: 7185, groups: id, 160 ## ## Fixed effects: ## Estimate Std. Error t value ## (Intercept) 12.7905 0.2087 61.299 ## female -1.1824 0.1616 -7.317 ## sectorcatholic 1.2945 0.2927 4.423 ## ses 2.7274 0.1428 19.100 ## meanses 3.0441 0.3665 8.306 ## sectorcatholic:ses -1.3062 0.2097 -6.229 ## ## Correlation of Fixed Effects: ## (Intr) female sctrct ses meanss ## female -0.396 ## sectorcthlc -0.636 -0.012 ## ses 0.090 0.047 -0.040 ## meanses 0.213 0.028 -0.335 -0.212 ## sctrcthlc:s -0.105 -0.014 0.064 -0.645 -0.020 Understanding assumptions by breaking them: Level 1 heteroskedasticity - if high SES students have more variable math achievement than low SES students. Level 2 heteroskedasticity - if catholic schools are more variable (in their random offsets) than public schools. Level 1 exogeneity: if the association between SES and math acheivement is not linear. Level 2 exogeneity: this one is fine, as long as we have categorical level-2 predictors. (with categorical predictirs, we are always ``linear’’). For continuous level-2 predictors, we would need a linear relationship again. Assumptions 2, 4, and 6 can cause bias (i.e., relationship between variables in the ``structural’’ part of the model and the error terms. While assumptions 1, 3 and 5 can mess up variance components (ie., consistency of the standard errors, accuracy of the variance estimates, accuracy of confidence intervals and hypothesis tests). Centering your covariates Intercepts \\[ income_i = \\beta_0 + \\beta_1SAT_i + \\epsilon_i \\\\ \\hat{\\beta_0} = 1000 \\\\ \\hat{\\beta_1} = 3 \\] When intercepts are far away, we get a slight change in slope associated with a large change in intercept. They are quite correlated. With centering, changing the slope doesn’t really change the intercept. The intercept is more the overall mean, and therefore useful. Decoupling slope and intercept stops each one from messing with the other and aids in estimation - can end up with high or low random effects correlations if not centered. If you see that the random intercept and slope are correlated after mean centering, then this means the correlation is something structural about the data, not something mechanical about estimation. Group mean centering: intercepts are now means of the whole group (i.e., school). Individual level covariate now measures departure from the group the individual is in. \\(y_{ij} = \\alpha_j + \\beta_j(X_{ij} - \\bar{X}_j) + \\epsilon_{ij}\\) where \\(\\bar{X}_j = 500\\) Grand mean centering: intercepts are now adjusted means. \\(y_{ij} = \\alpha_j + \\beta_j(X_{ij} - \\bar{X}) + \\epsilon_{ij}\\) where \\(\\bar{X} = 500\\). Within versus between centering: Lecture 2.5 Part I: within versus between centering Dataset - birthweight and smoking (Swedish dataset). Level 1 - babies. Level 2 - mother. Can do between mother comparisons and within mother comparisons. Think about regression as a form of matching. Between mother confounders will be time invariant, while within mother confounders will be time variant. Why did the mother smoke for one pregnancy but not the other? Do we have a variable that identifies the reason? Like was she large and sedantary, then became a marathon runner. Cannot do age to age within comparisons - same mother giving birth at age 20 cannot be compaared to her later self giving birth at age 40 - this would need to be between mother. Though you could use age-adjusted birthweights for within comparisons. Estimating between: aggregate data to group level, then regress average birthweight onto the averages of the predictors. A kind of dose-response model. Averaging works for linear models. Estimating within: take out between variation and then regress - this is fixed effects regression. Alternative - within-group recentering (subtract mother-level means from outcomes?? and all covariates - see RH&amp;S pg 145). Estimating both with a MLM: We can allow for different within and between effects. So for birth \\(i\\) of mother \\(j\\): \\[ y_{ij} = \\beta_1 + B^W(S_{ij} - \\bar{S}_{.j}) + \\beta^B\\bar{S}_{.j} + \\xi_j + \\epsilon_{ij} \\] with \\(S_{ij}\\) smoking status and \\(\\bar{S}_j\\) average smoking status for mother \\(j\\). Here the notation is that \\(\\gamma_0\\) is \\(\\beta_1\\) (the fixed effects intercept) and \\(u_j\\) is \\(\\xi_j\\) (the random effect residual - random deviations for the \\(j\\) groups from the fixed effects intecept). \\(\\beta_1 = 3238gms\\), \\(\\beta^W = -105\\), \\(\\beta^B = 183\\). dat &lt;- dat %&gt;% group_by(mid) %&gt;% mutate(smokem = mean(smoke), smokec = smoke - smokem) mod5 &lt;- lmer(birthweight ~ 1 + smokec + smokem + (1 | mid), data = dat) Deviations from cluster means are automatically uncorrlelated with the group means - solution to one of the model assuptions (this is the hybrid model). Now the same model with the HSB data: \\[ y_{ij} = \\beta_{0j} + \\beta_wSES_{ij} + \\beta_b\\bar{SES}_j + \\epsilon_{ij} \\\\ \\beta_{ij} = \\gamma_0 + u_{0j} \\] Within coef estimates slope inside the school. Between coef estimates how the averages of the school relate to the outcome. Contextual effect: The expected difference in outcomes from being in school 2 versus school 1 (but with the same SES) - in R&amp;B pg 140. The between effect is basically the contextual effect plus the within effect. If you group mean center the within variable, then the between variable becomes and estimate of the contextual effect - is this right? Part II: Concept of maximum likelihood The model: a description or recipe of how the data might have come to be (a data generating process). The model tells us what predictions are possible. The parameters: numbers that makes this general recipe more specific. What parameters of this model make your data more likely? Lecture 2.6 Inference for MLMs We get 3 things from MLMs: fixed effects variance and covariance parameters (\\(\\tau\\)) - variances and covariances of the hyperparameters With empirical Bayes as a second step, estimated random effects for each group (not the variances, but the actual estimates for each group). Inference for these estimates is very shaky - generally don’t do it. Second level predictors modify intercepts or slopes. If they modify slopes, then that is an interaction with the first level predictor associated with that slope - it moderates the slope of the first level predictor. See Chapter 4 in BR book. confidence intervals normal approximation: \\[ \\sqrt{n} \\left( \\hat{\\beta} - \\beta \\right) \\rightarrow N(0, \\tau^2) \\\\ SE = \\frac{\\tau}{\\sqrt{n}} \\] As sample size grows, the estimated parameters will be normally distributed about the true parameters, and the variance will shrink with the sample size towards an estimable value. If the sampling distribution is relatively symmetric and bell-shaped, a 95% confidence interval can be estimated using: \\[ statistic \\pm 2 \\times \\widehat{SE} \\] Confidence intervals don’t tell you whether you’re right or wrong for a given project, but rather how often you’ll be right over time. Normal approximation assumes that we know \\(\\tau\\), but we don’t, we estimate it. variance covariance estimates: Uncertainty estimnates are hard to get and are generally unreliable. But, we can test whether the estimates are different from zero. There are no standard errors for variance parameters - because standard errors only really make sense if the distribution is the estimator is more or less symmetric. But, for variance parameters, the distribution is skewed (bounded at zero). This boundary distorts normality. profile likelihood confidence intervals: Basically asks, “what is likely if we let other parameters fit as best they can?”. Lays down a number line and sets grid points, then iterates over the grid and determines which values on the grid are believable. Inference Compare your data to what you would have gotten were your hull hypothesis true (i.e., compare what we have to what we should have had). Likelihood ratio tests best Wald tests good, but not good for variance parameters with skewed distributions ANOVA / F tests score tests P-values: Gelman “There are no zeros in social science”. Wald test (t-test): \\[ t = \\frac{\\hat{\\beta} - \\beta_{hyp}}{\\widehat{se}(\\hat{\\beta})} \\] The chance of reaching your “extreme value” \\(t\\) by chance if the null hypothesis is correct. A problem with t-tests - degrees of freedom. \\[ H_0 : \\gamma_{10} = 0 \\] where: \\[ \\beta_{1j} = \\gamma_{10} + u_{1j} \\] The above null should be extended to include a test of whether the random effects variance for \\(u_{1j}\\) is also zero - in other words, no variance around the fixed effect of zero. By hand: 2 * pnorm(t, lower.tail = FALSE) The number of degrees of freedom tells you which parameters were harder or easier to estimate given the clustered nature of the data. Group mean centering can increase degrees of freedom. Likelihood ratio test: if the likelihoods are basically the same, we accept the null. If the constrained model fits like crap, then we reject the null. To test, we compare the ratio of likelihoods. Basic idea: if \\(\\gamma_{00}\\) is actually 0, then omitting it from the model shouldn’t make much difference. \\[ D = -2log \\frac{L(\\textrm{simple model})}{L(\\textrm{complex model})} \\] The likelihood ratio statistic has a \\(\\chi^2\\) distribution: \\[ D \\sim \\chi^2 \\] "],
["growth-curves.html", "Growth curves Lecture 3.1 Lecture 3.2 Lecture 3.2 Lecture 3.3", " Growth curves Longitudinal data and growth curves Lecture 3.1 Individuals are level 2, time is level 1. Observations about individuals that do not change are level 2, while observations about individuals that do change are level 1. Essentially, individuals are sampled, and then time points within individuals are sampled (not they’re not really sampled). Clustered data: we observed a bunch of students in a school. The students have no order. They are independent within the school. Longitudinal data: we observe a bunch of times. The times are ordered. They are not independent within the student. This ordering of observations is meaningful. So, time points closer to each other are more correlated with each other. Visualizations important with longitudinal data. Always look at your individuals by plotting their outcome data over time. Marginal model: summary / average accross all individuals. Read Willet and Singer book chapters. Panel studies: track everyone at the same sequence of time points. Timepoints are called “waves”. Cohort studies: follow a group. But, check-in times can be variable. Balance: For panel data, when there is an observation for each person at each time point. Growth curves R&amp;B pg 164 For each child, they have initial knowledge \\(\\pi_{0i}\\) and rate of increase \\(\\pi_{1i}\\). Make the intercept meaningful - at onset of preschool or something. R&amp;B pg 163-164 Classic random slope model: \\[ Y_{ti} = \\pi_{0i} + \\pi_{1i}\\alpha_{ti} + \\epsilon_{ti} \\\\ \\epsilon_{ti} \\sim N(0, \\sigma^2) \\\\ \\pi_{0i} = \\beta_{00} + r_{0i} \\\\ \\pi_{1i} = \\beta_{10} + r_{1i} \\\\ (r_{0i}, r_{1i}) \\sim N(\\bf{0}, \\Sigma) \\] Fixed effects: \\(\\beta_{00}\\), \\(\\beta_{10}\\) Variance components: \\(\\sigma^2\\), \\(\\tau_{00}\\), \\(\\tau_{11}\\), \\(\\tau_{10}\\) Betas are now parameters at level 2 because we added in another level below individuals. Lecture 3.2 Quadratic Growth Models (Part I) Questions to ask: 1. Is there variation? — are these children different from each other? 2. What explains this variation? — what variables explain why children are different from one another? 3 random effects per student: 1. Random intercept (\\(\\pi_{0i}\\)) 2. Random slope (\\(\\pi_{1i}\\)) 3. Random acceleration /curvature (growth) (\\(\\pi_{2i}\\)) Data is structured like this: ID \\(\\alpha\\) \\(\\gamma\\) Home Language HRS 101 \\(\\alpha_{1, 101}\\) 0 -0.5 0 80 101 \\(\\alpha_{2, 101}\\) 4 0.2 0 80 101 \\(\\alpha_{3, 101}\\) 5 0.4 0 80 101 \\(\\alpha_{4, 101}\\) 8 0.7 0 80 208 \\(\\alpha_{1, 208}\\) -0.8 1 80 First column after ID is time. Two level notation: (here, \\(a\\) is age - a level one predictor) \\[ Y_{ti} = \\pi_{0i} + \\pi_{1i}a_{ti} + \\epsilon_{ti} \\\\ \\epsilon_{ti} \\sim N(0, \\sigma^2) \\\\ \\pi_{0i} = \\beta_{00} + \\beta_{01}X_i + r_{0i} \\\\ \\pi_{1i} = \\beta_{10} + \\beta_{11}X_i + r_{1i} \\\\ (r_{0i}, r_{1i}) \\sim N(\\bf{0}, \\Sigma) \\] Single level notation: \\[ Y_{ti} = \\pi_{0i} + \\pi_{1i}a_{ti} + \\epsilon_{ti} \\\\ = (\\beta_{00} + \\beta_{01}X_i + r_{0i}) + (\\beta_{10} + \\beta_{11}X_i + r_{1i}) + a_{ti} + \\epsilon_{ti} \\\\ = \\beta_{00} + \\beta_{01}X_i + r_{0i} + \\beta_{10}a_{ti} + \\beta_{11}X_i\\alpha_{ti} + r_{1i}a_{ti} + \\epsilon_{ti} \\\\ = \\beta_{00} + \\beta_{01}X_i + \\beta_{10}a_{ti} + \\beta_{11}X_ia_{ti} + (r_{0i} + r_{1i}a_{ti} + \\epsilon_{ti}) \\] The random effects in the parentheses on the final line can be thought of as residuals. Prediction: \\[ X_i = 2, a_{ti} = 5 \\\\ \\beta_{00} + \\beta_{01}2 + \\beta_{10}5 + \\beta_{11}2.5 \\] mod7 &lt;- lmer(Y ~ 1 + age * (language + hours) + (1 + age | StudentID), data = dat) When using growth models, we may not care about level 1. Level 2 is where we get at the question of growth. Here, \\(t\\) is the observation number. \\[ Y_{ti} = \\pi_{0i} + \\pi_{1i}a_{ti} + \\epsilon_{ti} \\\\ \\epsilon_{ti} \\sim N(0, \\sigma^2) \\\\ \\pi_{0i} = \\beta_{00} + \\beta_{01}LANG_i + \\beta_{02}HRS_i + r_{0i} \\\\ \\pi_{1i} = \\beta_{10} + \\beta_{11}LANG_i + \\beta_{12}HRS_i + r_{1i} \\\\ (r_{0i}, r_{1i}) \\sim N(\\bf{0}, \\Sigma) \\] When looking at growth rates over time, a small growth rate difference can mean a lot, since the difference in growth rate gets compounded over time. It’s best to get some predictions for each kid over the full length of time, then compare. Quadratic growth (R&amp;B chapter 6) Research question: Describe the association between maternal speech and child’s vocabulary. Very important to pick where the intercept is for growth models — need to mean center. L is an important centering decision - in this case, L = 12 months (that’s the intercept). But, may be better to put L within the bounds of the observed data. \\(\\pi_{0i}\\) = status at L \\(\\pi_{1i}\\) = instantaneous (average) growth at L \\(\\pi_{2i}\\) = curvature / acceleration Unconditional Quadratic Growth Model: \\[ Y_{ti} = \\pi_{0i} + \\pi_{1i}(a_{ti} - L) + \\pi_{2i}(a_{ti} - L)^2 + \\epsilon_{ti} \\\\ \\epsilon_{ti} \\sim N(0, \\sigma^2) \\\\ \\pi_{0i} = \\gamma_{00} + u_{0i} \\\\ \\pi_{1i} = \\gamma_{01} + u_{1i} \\\\ \\pi_{2i} = \\gamma_{02} + u_{2i} \\\\ (u_{0i}, u_{1i}, u_{2i}) \\sim N(\\bf{0}, \\Sigma) \\] Three random effects — all correlated. We have a fixed centering constant \\(L\\) (this is a constant chosen by you, not a parameter). Anything with an \\(i\\) subscript is for an individual student. Anything without a subscript is a fixed effect — this is the shared structual component of the model. Number of parameters we are estimating: 3 fixed effects: \\(\\gamma_{00}, \\gamma_{01}, \\gamma_{02}\\) 6 random effects: the diagonals of the matrix: \\(\\tau_{00}, \\tau_{11}, \\tau_{22}\\). next are the covariances: \\(\\tau_{01}, \\tau_{02}, \\tau_{12}\\) 1 residual term: \\(\\epsilon_{ti}\\) Lecture 3.2 Quadratic Growth Models (Part II) R&amp;B Chapter 6 pg 169-176 Anatomy of a quadratic curve: \\[ y = \\pi_{oi} + \\pi_{1i}(X - L) + \\pi_{2i}(X - L)^2 \\\\ L = 19 \\\\ X = {18, 19, 20} \\\\ \\pi_{0i} = 1, \\pi_{1i} = 2, \\pi_{2i} = 0.5 \\] Evaluate y at the above Xs and graph it. Predict vocabulary for an average / typical child (assuming the random effects and residuals are zero) at X = 20 and X = 12: \\[ \\hat{y} = -45.05 + 12.14(20 - 12) + 1.84(20 - 12)^2 \\\\ = 170 \\\\ \\hat{y} = -45.05 + 12.14(12 - 12) + 1.84(12 - 12)^2 \\\\ = -45.05 \\] If the random effects are not normally distributed (the ones from the coef() function in R), then this is evidence of model miss-specification. Probably, there is some omitted variable in the structural part of the model. If the random effects are grouped at the extremes, this may indicate that there’s a missing grouping variable in the fixed effects part of the model. Rate of growth at age \\(a\\) for kid \\(i\\) is the derivitive of our curve at age \\(a\\). Model Building How can we get a nice simple model given our data? (Cat lego picture) Model refinements: Drop the intercept — no overall intercept or random intercept. We force the regression through the origin, which if we’ve centered the data at \\(L = 12\\) the origin will be 12. So, kids at age 12 will have zero vocabularly. Our residuals only changed a little bit. Set expected rate of growth at age 12 to zero. (i.e., take out the linear fixed effect term, but leave in the linear random effect). Our residuals only changed a little bit. Adding covariates Can we explain our acceleration? Is maternal speech predictive of growth? Dropping main effects — a design decision: M4A.2 &lt;- lmer(vocab ~ 0 + age12sq:sex + age12sq:logmom + (0 + age12 + age12sq | per), dat = dat.g0) The above model says that mother’s vocabularly will increase the accelation of child’s acquisition of vocabularly. But, that the fixed rate of growth (i.e., linear growth) is fixed at zero. Lecture 3.3 piecewise linear growth model and model comparison (AIC) Reading: Faraway ch 9. Rabe-Hesketh &amp; Skrondal: pp 227-264 logitudinal data structure, pp 278-282 missing data, pp 293-311 marginal models and error structures. Time varying questions are harder than time invariant questions. screenreg() from textregp package (can it output SDs instead of variances?) Positive covariance term means that higher random slope goes with higher random intercept - so kids that start with higher reading skills also learn at a faster rate. Even if the difference in learning rate is small between the kids, over time this can equate to a large difference in their reading skills. \\[ covariance(A, B) = correlation \\times SD_A \\times SD_B \\\\ correlation = \\frac{covariance}{SD_A \\times SD_B} \\] mod9 &lt;- lmer(reading ~ 1 + time + gender + time : gender + (1 + time | id), data = dat) Comparing models \\[ 1 - Var(conditional model) / Var(unconditional model) = proportion of variance explained \\] Parametric growth curves The most complex model you can entertain is one where the number of parameters is n-1, where n is the number of observations. So if there are 4 data points for each kid, you can have at most a quadratic model. Can use a log transform to have a steep start to the growth, then have it level out. Selecting a growth curve use theory / research question use a curve that works well overall simple is better Piecewise growth Piecewise growth is inherently cumulative. \\[ reading_{it} = \\pi_{0i} + \\pi_{1i}TimeA_{it} + \\pi_{2i}TimeB_{it} + \\epsilon_{it} \\] Look at cumulative school time and cumulative summer time (do book keeping based on data collection) Option 1: school time / summer time separately: \\[ reading_{it} = \\pi_{0i} + \\pi_{1i}School_{it} + \\pi_{2i}Summer_{it} + \\epsilon_{it} \\\\ \\pi_{0i} = \\gamma_{00} + u_{0i} \\\\ \\pi_{1i} = \\gamma_{10} + u_{1i} \\\\ \\pi_{2i} = \\gamma_{20} + u_{2i} \\] mod10 &lt;- lmer(reading ~ 1 + school + summer + (1 + school + summer | id), data = dat) Option 2: increment / decrement — like an interaction for the change in slope at a specific time point: \\[ reading_{it} = \\pi_{0i} + \\pi_{1i}Time_{it} + \\pi_{2i}Summer_{it} + \\epsilon_{it} \\\\ \\pi_{0i} = \\gamma_{00} + u_{0i} \\\\ \\pi_{1i} = \\gamma_{10} + u_{1i} \\\\ \\pi_{2i} = \\gamma_{20} + u_{2i} \\] mod11 &lt;- lmer(reading ~ 1 + time + summer + (1 + time + summer | id), data = dat) These two models are the same; they just have different parameterizations. "],
["many-level-models.html", "Many level models Lecture 4.1 Lecture 4.2 (A) Lecture 4.2 (B) Lecture 4.3", " Many level models Lecture 4.1 Many level models (&gt;3 levels) Case study: student growth for student nested in schools — READS data. Student level predictors, but students are within schools. Research questions: Do students at different schools grow at different rates, on average? Do students identified at English learners language learners grow at different rates than other students, and does that vary by school? (this requires a student-level predictor) Do students at high poverty schools have systematically different rates of growth than students at low poverty schools (this requires a school-level predictor). Three-level model: \\[ read_{ijt} = \\pi_{0ij} + \\pi_{1ij}time_{ijt} + \\color{darkgreen}{\\epsilon_{ijt}} \\\\ \\color{darkgreen}{\\epsilon_{ijt}} \\sim N(0, \\sigma^2) \\\\ \\pi_{0ij} = \\beta_{00j} + \\color{darkgreen}{u_{0ij}} \\\\ \\pi_{1ij} = \\beta_{10j} + \\color{darkgreen}{u_{1ij}} \\\\ \\beta_{00j} = \\color{darkred}{\\gamma_{000}} + \\color{darkgreen}{r_{00j}} \\\\ \\beta_{10j} = \\color{darkred}{\\gamma_{100}} + \\color{darkgreen}{r_{10j}} \\\\ (u_{0ij}, u_{1ij}) \\sim N(\\bf{0}, \\Sigma) \\\\ (r_{00j}, r_{10j}) \\sim N(\\bf{0}, \\tau) \\] Outcome deoends on level 1 things, then how level 2 things depend on level 1 things, then how level 3 things depend on level 2 things. (last two lines of equation above are not correct) \\(\\beta\\) is about specific schools (level 2), while \\(\\gamma\\) is across the whole population (level 3). R syntax: mod11 &lt;- lmer(read ~ 1 + time + (1 + time | id) + (1 + time | schid), data = dat) ## same as mod11 &lt;- lmer(read ~ 1 + time + (1 + time | id/schid), data = dat) ## same as mod11 &lt;- lmer(read ~ 1 + time + (1 + time | id:schid) + (1 + time | schid), data = dat) Reduced form (substitute the \\(\\pi\\)’s): \\[ Y_{ijt} = \\pi_{0ij} + \\pi_{1ij}time_{ijt} + \\epsilon_{ijt} \\\\ = (\\beta_{00j} + u_{0ij}) + (\\beta_{10j} + u_{1ij})time_{ijt} + \\epsilon_{ijt} \\\\ = \\beta_{00j} + \\beta_{10j}time_{ijt} + u_{0ij} + u_{1ij} \\epsilon_{ijt} \\\\ = (\\gamma_{000} + r_{00j}) + (\\gamma_{100} + r_{10j}) + u_{0ij} + u_{1ij} time_{ijt} + \\epsilon_{ijt} \\\\ = \\color{darkred}{\\gamma_{000} + \\gamma_{100}time_{ijt}} + \\color{darkgreen}{r_{00j} + r_{10j}time_{ijt} + u_{0ij} + u_{1ij}time_{ijt} + \\epsilon_{ijt}} \\] Offset due to schools are the \\(r\\)’s. Offset due to students are the \\(u\\)’s. The \\(\\epsilon_{ijt}\\) is the same sort of error as in single-level OLS (i.e., measurement error). The random effect ‘stack’ on top of each other. Fixed effect population averages are in \\(\\color{darkred}{darkred}\\), while residuals are in \\(\\color{darkgreen}{darkgreen}\\). You could have the higher level (level 3 here) be fixed effects only — so if you only had 5 schools, this could be a 2-level mixed model for students over time with fixed effects for school. Level 2 covariates Including student ELL status (time-invariant) in the two-level form: \\[ read_{ijt} = \\pi_{0ij} + \\pi_{1ij}time_{ijt} + \\color{darkgreen}{\\epsilon_{ijt}} \\\\ \\color{darkgreen}{\\epsilon_{ijt}} \\sim N(0, \\sigma^2) \\\\ \\pi_{0ij} = \\beta_{00j} + \\beta_{01j}ELL_{ij} + \\color{darkgreen}{u_{0ij}} \\\\ \\pi_{1ij} = \\beta_{10j} + \\beta_{11j}ELL_{ij} + \\color{darkgreen}{u_{1ij}} \\\\ \\color{grey}{\\textrm{average school reading score:}} \\quad \\beta_{00j} = \\color{darkred}{\\gamma_{000}} + \\color{darkgreen}{r_{00j}} \\\\ \\color{grey}{\\textrm{school-specific ELL initial gap:}} \\quad \\beta_{01j} = \\color{darkred}{\\gamma_{010}} + \\color{darkgreen}{r_{01j}} \\\\ \\color{grey}{\\textrm{school avarge growth rate:}} \\quad \\beta_{10j} = \\color{darkred}{\\gamma_{100}} + \\color{darkgreen}{r_{10j}} \\\\ \\color{grey}{\\textrm{school specific ELL/non-ELL growth rate:}} \\quad \\beta_{11j} = \\color{darkred}{\\gamma_{110}} + \\color{darkgreen}{r_{11j}} \\\\ \\] We have four 3rd-level equations. We now have a \\(4 \\times 4\\) matrix for the random effects. Reduced form: \\[ read_{ijt}= \\color{darkred}{\\gamma_{000} + \\gamma_{010}ELL_{ij} + \\gamma_{100}time_{ijt} + \\gamma_{110}ELL_{ij}time_{ijt}} + \\color{darkgreen}{r_{00j} + r_{01j}ELL_{ij} + r_{10j}time_{ijt} + r_{11j}time_{ijt}ELL_{ij} + u_{0ij} + u_{1ij}time_{ijt} + \\epsilon_{ijt}} \\] R model syntax: mod11 &lt;- lmer(read ~ 1 + time * ell + (1 + time | id) + (1 + time * ell | schid), data = dat) Level 3 covariates How does poverty interact with growth (school level) Including school poverty variable in the two-level form: SEE PHOTO!!!! the below equation is not correct, just the same as above. \\[ read_{ijt} = \\pi_{0ij} + \\pi_{1ij}time_{ijt} + \\color{darkgreen}{\\epsilon_{ijt}} \\\\ \\color{darkgreen}{\\epsilon_{ijt}} \\sim N(0, \\sigma^2) \\\\ \\pi_{0ij} = \\beta_{00j} + \\beta_{01j}ELL_{ij} + \\color{darkgreen}{u_{0ij}} \\\\ \\pi_{1ij} = \\beta_{10j} + \\beta_{11j}ELL_{ij} + \\color{darkgreen}{u_{1ij}} \\\\ \\color{grey}{\\textrm{average school reading score:}} \\quad \\beta_{00j} = \\color{darkred}{\\gamma_{000}} + \\color{darkgreen}{r_{00j}} \\\\ \\color{grey}{\\textrm{school-specific ELL initial gap:}} \\quad \\beta_{01j} = \\color{darkred}{\\gamma_{010}} + \\color{darkgreen}{r_{01j}} \\\\ \\color{grey}{\\textrm{school avarge growth rate:}} \\quad \\beta_{10j} = \\color{darkred}{\\gamma_{100}} + \\color{darkgreen}{r_{10j}} \\\\ \\color{grey}{\\textrm{school specific ELL/non-ELL growth rate:}} \\quad \\beta_{11j} = \\color{darkred}{\\gamma_{110}} + \\color{darkgreen}{r_{11j}} \\\\ \\] R model syntax (with 3-way interaction): mod12 &lt;- lmer(read ~ 1 + time * ell * poverty_school + (1 + time | id) + (1 + time * ell | schid), data = dat) Split initial ability (intercepts) and growth rate (time) equations: \\[ read_{ijt} = (\\gamma_{000} + \\gamma_{010}ELL_{ij} + \\gamma_{001}Poverty_{j} + \\gamma_{011}ELL_{ij}Poverty_{j}) + \\\\ (\\gamma_{100} + \\gamma_{110}ELL_{ij} + \\gamma_{101}Poverty + \\gamma_{111}ELL_{ij}Poverty_{j}) * time_{ijt} \\] Lecture 4.2 (A) Crossed Random Effects Models Cross-classified models arise when we have multiple nesting structures (e.g., when each observation can be classified into multiple different level-2 units). For example, students are nested in both schools and neighborhoods. Lecture 4.2 (B) AIC and Model Selection / Building (model search) Picking from a bunch of different models that are not nested. R&amp;B ch 9, 252-276. Options for model selection (statistical tools): Likelihood Ratio Tests Cannot do likelihood ratio testing on non-nested models. need to fit the models to exactly the same data Model inspection / evaluation AIC / BIC / etc. penalizes more complicated models can compare non-nested models can compare whole families of models need to fit the models to exactly the same data Complexity versus model fit: more parameters means more flexible, but the model is more complicated. AIC: a measure of the relative quality of statistical models: \\[ AIC = -2(LL) + 2k \\] Where \\(k\\) is the number of parameters and \\(LL\\) is the log-likelihood. BIC &amp; DIC: measures of the relative quality of statistical models: \\[ BIC = -2(LL) + log(n)k \\\\ DIC = -2(LL) + k_D \\] Sample size for BIC? Should it be number of units at level 1 — super conservative (does not take into account the nested structure of data)? Or number of level 2 units — less conservative? Information criteria should get the gross ordering of good vs. bad models right. Then use LRTs for specific terms between the good models. Always plot the data. Lecture 4.3 Randomized Experiments Custer randomized experiments (each school gets treated or not). Multisite randomized experiments (a bunch of schools, where a fraction of the students in each get treated). Each school is a mini-experiment, and you can see how these experiments differ across schools. Randomized experiments: The experimenter obtains a collection of units, then randomized units into treatment and control. This makes, for typical randomizations, the treatment group and the control group more or less the same. Now, if we see any differences in outcome, we can ascribe this to the treatment itself. Potential outcomes The Neyman-Rubin potential outcomes framework: Assume treatment assignment for any unit has no impact on any other unit (SUTVA). Each unit has two outcomes; \\(y(1)\\): what happens when you treat it \\(y(0)\\): what happens when you do not The treatment effect for unit \\(i\\) is then \\(\\tau = y(1) - y(0)\\). We observe either \\(y(1)\\) or \\(y(0)\\) depending on whether we treat unit \\(i\\) or not. The potential outcomes are fixed. The randomness comes from how treatment is assigned. How treatment is assigned is called the assignment mechanism. In a potential outcomes framework, randomness is due to assignment, the units can be considered fixed. The key idea is that any individual has two outcomes, only one of which we see. Cluster Randomized Trials Must take clustering into account when modeling these designs. What are we estimating? Average treatment effect of sites Average treatment effect of people \\[ Y_{ij} = \\beta_j + r_{ij} \\\\ \\beta_j = \\gamma_0 + \\gamma_1T_j + u_j \\\\ u_j \\sim N(0, \\sigma^2_u) \\] Treatment, \\(T_j\\), is a level-2 variable. We cannot separate variation in treatment impact and variation in clusters. We might reasonably worry about the 2nd-level variance term: we could let it vary by treatment status with an extended model with different variances for the treatment groups. mod14 &lt;- lmer(year ~ 1 + T + (1 | schid), data = dat) How many units? If the clusters are radically different and the units within a cluster very much the same, then we really have only \\(j\\) units in our experiment. If the clusters are the samne, and individuals within cluster basically independent, then we have closer to \\(nJ\\) units. Moral: cluster-randomization can be a much smaller experiment than you think. Rough estimate of uncertainty: \\[ \\hat{\\gamma_1} = \\hat{Y_T} - \\hat{Y_C} \\\\ Var(\\hat{\\gamma_1}) = \\frac{1}{J} \\left( 4\\sigma^2_u + \\frac{\\sigma^2}{n} \\right) \\] Cost of data collection: \\[ Cost = J(C_{1n} + C_2) \\] You can do power and optimal cost/design calculations for specific scenarios but they may not generalize. Could instead simulate to model more complex and authentic scenarios. ICC strongly affects power: as ICC gets bigger you need more clusters (more clusters rather than a few big clusters). Can get ICC from pilot studies or previous research to use in power analysis. Multisite Experiments Each site is a mini-experiment, but they are related. Research questions: What is the average impact across sites? What is the variation in impacts across sites? What is the impact for a specific site? (Harder - comes from empirical Bayes estimates) Compared to cluster randomization: here we get treatment info. for each site. Cluster-randomization gives no treatment info. for any site. This means we have more power, because we can assess the site impact as well as the treatment impact. Model - two-level notation: \\[ Y_{ij} = \\beta_{0j} + \\beta_{1j}T_{ij} + \\color{darkgreen}{r_{ij}} \\\\ \\color{darkgreen}{r_{ij}} \\sim N(0, \\sigma^2) \\\\ \\beta_{0j} = \\color{darkred}{\\gamma_{00}} + \\color{darkgreen}{u_{0j}} \\\\ \\beta_{1j} = \\color{darkred}{\\gamma_{10}} + \\color{darkgreen}{u_{1j}} \\\\ \\left( \\frac{u_{0j}}{u_{1j}} \\right) \\sim N \\left[\\frac{0}{0} ? \\right] \\] "]
]
